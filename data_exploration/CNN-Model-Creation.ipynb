{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7027cc2",
   "metadata": {},
   "source": [
    "## This notebook was for the first cut solution of a CNN + for evaluating the different dataset we generated from our data in accordance with the CNN predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43598701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 10:36:48.909334: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:36:49.070191: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:36:49.070219: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-07 10:36:49.969201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:36:49.969368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:36:49.969378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Embedding,GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.layers import Dense, Dropout, Conv1D, MaxPool1D, GlobalMaxPool1D, Embedding, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras_visualizer import visualizer \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "import visualkeras\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing and model is used from \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2446eea8",
   "metadata": {},
   "source": [
    "## Adapt the preprocessing pipeline to the songs so thath the input is cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0cdeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 10:36:52.133273: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-07 10:36:52.133589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:36:52.133668: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:36:52.133736: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:36:52.133802: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:36:52.133868: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:36:52.133934: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:36:52.133998: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:36:52.134063: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:36:52.134075: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def tokenization(text):\n",
    "    \"\"\"Use this function to tokenize text.\n",
    "\n",
    "    :param text: Text as list\n",
    "    :type text: list[spacy.tokens.token.Token]\n",
    "    :return: Tokenized text as list\n",
    "    :rtype: list[spacy.tokens.token.Token]\n",
    "    \"\"\"\n",
    "\n",
    "    token_list = []\n",
    "    for doc in text: \n",
    "        # iterate over tokens in docs\n",
    "        for token in doc:\n",
    "            token_list.append(token)\n",
    "\n",
    "    return token_list\n",
    "\n",
    "\n",
    "def stop_word_removal(text): \n",
    "    \"\"\"Use this function to remove stop words. \n",
    "\n",
    "    :param text: Tokens to remove stop words from \n",
    "    :type text: list[spacy.tokens.token.Token]\n",
    "    :return: Tokens without stop words\n",
    "    :rtype: list[spacy.tokens.token.Token]\n",
    "    \"\"\"\n",
    "\n",
    "    token_list_without_stop = []\n",
    "    # Don't add token to list if stop word\n",
    "    for token in text:\n",
    "        if token.is_stop == False: \n",
    "            token_list_without_stop.append(token)\n",
    "\n",
    "    return token_list_without_stop\n",
    "\n",
    "\n",
    "def punctutation_removal(text): \n",
    "    \"\"\"Use this function to remove punctuation.\n",
    "\n",
    "    :param text: Tokens to remove punctuation from\n",
    "    :type text: list[spacy.tokens.token.Token]\n",
    "    :return: Tokens without punctuation\n",
    "    :rtype: list[spacy.tokens.token.Token]\n",
    "    \"\"\"\n",
    "\n",
    "    token_list_no_stop_no_punct = []\n",
    "    # Don't add token to list if punctuation\n",
    "    for token in text:\n",
    "        if token.is_punct == False:\n",
    "            token_list_no_stop_no_punct.append(token)\n",
    "\n",
    "    return token_list_no_stop_no_punct\n",
    "\n",
    "\n",
    "def lemmatization(text): \n",
    "    \"\"\"Use this function to lemmatize a given text.\n",
    "\n",
    "    :param text: Tokens to lemmatize\n",
    "    :type text: list[spacy.tokens.token.Token]\n",
    "    :return: lemmatized tokens\n",
    "    :rtype: list[str]\n",
    "    \"\"\"\n",
    "\n",
    "    token_list_no_stop_no_punct_lemmatized = []\n",
    "    for token in text: \n",
    "        if \"\\n\" not in token.lemma_:\n",
    "            token_list_no_stop_no_punct_lemmatized.append(token.lemma_)\n",
    "    return token_list_no_stop_no_punct_lemmatized\n",
    "\n",
    "\n",
    "def processing_pipeline(song_data):\n",
    "    \"\"\"Use this function to execute the entire processing pipeline on given song data.\n",
    "    Preprocessing steps:\n",
    "    - Tokenization\n",
    "    - Stop word removal\n",
    "    - Punctuation removal\n",
    "    - Lemmatization\n",
    "    - ...\n",
    "\n",
    "    :param song_data: song data saved in a json file containing song name, artist name and lyrics\n",
    "    :type song_data: dict\n",
    "    :return: preprocessed song data\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable = ['ner'])\n",
    "    \n",
    "    for row in range(len(song_data)):\n",
    "        text_nlp_pipe = list(nlp.pipe([song_data.iloc[row][\"Lyric\"]]))\n",
    "    \n",
    "        # Tokenization\n",
    "        song_data.at[row,\"Lyric\"] = tokenization(text_nlp_pipe)\n",
    "        # Stop word removal\n",
    "        song_data.at[row,\"Lyric\"] = stop_word_removal(song_data.iloc[row][\"Lyric\"])\n",
    "        # Punctuation removal\n",
    "        song_data.at[row,\"Lyric\"] = punctutation_removal(song_data.iloc[row][\"Lyric\"])\n",
    "        # Lemmatization\n",
    "        song_data.at[row,\"Lyric\"] = lemmatization(song_data.iloc[row][\"Lyric\"])\n",
    "        song_data.at[row,\"Lyric\"] = \" \".join(song_data.iloc[row][\"Lyric\"])\n",
    "        song_data.at[row,\"Lyric\"] = song_data.iloc[row][\"Lyric\"].lower()\n",
    "        if row%500 == 0 and row >= 500:\n",
    "            print(f\"processsed: {row} rows out of {len(song_data)}\")\n",
    "    return song_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f400ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to use the word2vec as an layer in keras \n",
    "# taken from the gensim wikipage: https://github.com/RaRe-Technologies/gensim/wiki/Using-Gensim-Embeddings-with-Keras-and-Tensorflow\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def gensim_to_keras_embedding(model, train_embeddings=False):\n",
    "    \"\"\"Get a Keras 'Embedding' layer with weights set from Word2Vec model's learned word embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_embeddings : bool\n",
    "        If False, the returned weights are frozen and stopped from being updated.\n",
    "        If True, the weights can / will be further updated in Keras.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `keras.layers.Embedding`\n",
    "        Embedding layer, to be used as input to deeper network layers.\n",
    "\n",
    "    \"\"\"\n",
    "    keyed_vectors = model.wv  # structure holding the result of training\n",
    "    weights = keyed_vectors.vectors  # vectors themselves, a 2D numpy array    \n",
    "    index_to_key = keyed_vectors.index_to_key  # which row in `weights` corresponds to which word?\n",
    "\n",
    "    layer = Embedding(\n",
    "        input_dim=weights.shape[0],\n",
    "        output_dim=weights.shape[1],\n",
    "        weights=[weights],\n",
    "        trainable=train_embeddings,\n",
    "    )\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb8a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def create_model(density, word2vecmodel,mood_count,filters,multiplicator, multiplicator2, kernel, outputfunction):\n",
    "    keras_model = Sequential()\n",
    "    keras_model.add(gensim_to_keras_embedding(word2vecmodel, True))\n",
    "    keras_model.add(Dropout(0.2))\n",
    "    keras_model.add(Conv1D(filters, kernel, activation='relu', padding='same', strides=1))\n",
    "    keras_model.add(Conv1D(filters, kernel, activation='relu', padding='same', strides=1))\n",
    "    keras_model.add(MaxPool1D())\n",
    "    keras_model.add(Dropout(0.2))\n",
    "    keras_model.add(Conv1D(filters*multiplicator, kernel, activation='relu', padding='same', strides=1))\n",
    "    keras_model.add(Conv1D(filters*multiplicator, kernel, activation='relu', padding='same', strides=1))\n",
    "    keras_model.add(MaxPool1D())\n",
    "    keras_model.add(Dropout(0.2))\n",
    "    keras_model.add(Conv1D(filters*multiplicator2, kernel, activation='relu', padding='same', strides=1))\n",
    "    keras_model.add(Conv1D(filters*multiplicator2, kernel, activation='relu', padding='same', strides=1))\n",
    "    keras_model.add(GlobalMaxPool1D())\n",
    "    keras_model.add(Dropout(0.2))\n",
    "    keras_model.add(Dense(density))\n",
    "    keras_model.add(Activation('relu'))\n",
    "    keras_model.add(Dropout(0.2))\n",
    "    # Number of moods to be classified to\n",
    "    keras_model.add(Dense(mood_count))\n",
    "    keras_model.add(Activation(outputfunction))\n",
    "    \n",
    "    keras_model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    \n",
    "    return keras_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d1d447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(grid_result):\n",
    "    \n",
    "    # get the results of GridSearchCV\n",
    "    results = grid_result.cv_results_\n",
    "\n",
    "    # create a list of the parameter settings for the x-axis\n",
    "    x_axis = range(len(results['params']))\n",
    "\n",
    "    # create a list of the mean test scores for the y-axis\n",
    "    y_axis = results['mean_test_score']\n",
    "\n",
    "    # create a bar chart of the mean test scores\n",
    "    plt.bar(x_axis, y_axis, align='center')\n",
    "\n",
    "    # set the x-axis tick labels to the parameter settings\n",
    "    plt.xticks(x_axis, results['params'], rotation=90)\n",
    "\n",
    "    # add a title and axis labels\n",
    "    plt.title('GridSearchCV Results')\n",
    "    plt.xlabel('Parameter Settings')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    # display the graph\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad98c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_dataset(dataset_path, mood_count):\n",
    "    print(f\"Testing now dataset {dataset_path} with {mood_count} moods\")\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print((df[\"Mood\"].unique()))\n",
    "    df = processing_pipeline(df)\n",
    "    list(df[\"Lyric\"].head(2))\n",
    "    # merge lyrics together\n",
    "    lyrics = []\n",
    "    for i in df['Lyric']:\n",
    "        lyrics.append(i.split())\n",
    "    print(lyrics[:2])\n",
    "\n",
    "    # train the word2vec model\n",
    "    # vector size according to https://moj-analytical-services.github.io/NLP-guidance/NNmodels.html#:~:text=The%20standard%20Word2Vec%20pre%2Dtrained,fewer%20dimensions%20to%20represent%20them.\n",
    "    # mincount = 2 to prevent misspellings\n",
    "    word2vec_model = Word2Vec(lyrics, vector_size=150, window=5, min_count=2, workers=16)\n",
    "\n",
    "    # use the keras tokenizer and apply it to the lyrics\n",
    "    # number in first row is vocab size from word2vec model\n",
    "    token = Tokenizer(len(word2vec_model.wv))\n",
    "    token.fit_on_texts(df['Lyric'])\n",
    "    text = token.texts_to_sequences(df['Lyric'])\n",
    "    text = pad_sequences(text, 180)\n",
    "    print(text[3:5])\n",
    "\n",
    "    # encode the labels\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y = le.fit_transform(df['Mood'])\n",
    "    y = to_categorical(y)\n",
    "    # save the label encoder\n",
    "    np.save('data/label_encoder.npy', le.classes_)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(np.array(text), y, test_size=0.01, stratify=y)\n",
    "\n",
    "    \n",
    "    return  word2vec_model,x_train, x_test, y_train, y_test\n",
    "    \n",
    "def test_dataset(word2vec_model,x_train, x_test, y_train, y_test, mood_count):\n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    batch_size = 32\n",
    "    epochs = 3\n",
    "\n",
    "    model_CV = KerasClassifier(build_fn=create_model, epochs=epochs, \n",
    "                                   batch_size=batch_size, verbose=1)\n",
    "    # grid search parameters\n",
    "    filters = [50, 100]\n",
    "    multiplicator = [2,3]\n",
    "    multiplicator2 = [4,5]\n",
    "    kernel = [5]\n",
    "    outputfunction = [\"relu\",\"softmax\"]\n",
    "    word2vecmodel = [word2vec_model]\n",
    "    density = [200, 100]\n",
    "                      \n",
    "    scoring = {'accuracy': make_scorer(accuracy_score), 'f1': make_scorer(f1_score, average=\"weighted\")}\n",
    "\n",
    "    param_grid = {\n",
    "        \"density\": density,\n",
    "        \"word2vecmodel\": word2vecmodel,\n",
    "        \"mood_count\": [mood_count],\n",
    "        \"filters\": filters,\n",
    "        \"multiplicator\": multiplicator,\n",
    "        \"multiplicator2\": multiplicator2,\n",
    "        \"kernel\": kernel,\n",
    "        \"outputfunction\": outputfunction\n",
    "        }\n",
    "    grid = GridSearchCV(estimator=model_CV, param_grid=param_grid, n_jobs=-1,cv=2, error_score=\"raise\")\n",
    "    grid_result = grid.fit(x_train, y_train)\n",
    "    \n",
    "    # print results\n",
    "    print(f'Best Accuracy is: {grid_result.best_score_} using {grid_result.best_params_}')\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(f' mean={mean:.4}, std={stdev:.4} using {param}')\n",
    "    print(\"##\"*50)\n",
    "    \n",
    "    print_results(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648e2db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing now dataset ./data/song-data-labels-cleaned-seven-moods.csv with 7 moods\n",
      "['romantic' 'happy' 'sad' 'enthusiastic' 'calm' 'depressed' 'anger']\n",
      "processsed: 500 rows out of 14308\n",
      "processsed: 1000 rows out of 14308\n",
      "processsed: 1500 rows out of 14308\n",
      "processsed: 2000 rows out of 14308\n",
      "processsed: 2500 rows out of 14308\n",
      "processsed: 3000 rows out of 14308\n",
      "processsed: 3500 rows out of 14308\n",
      "processsed: 4000 rows out of 14308\n",
      "processsed: 4500 rows out of 14308\n",
      "processsed: 5000 rows out of 14308\n",
      "processsed: 5500 rows out of 14308\n",
      "processsed: 6000 rows out of 14308\n",
      "processsed: 6500 rows out of 14308\n",
      "processsed: 7000 rows out of 14308\n",
      "processsed: 7500 rows out of 14308\n",
      "processsed: 8000 rows out of 14308\n",
      "processsed: 8500 rows out of 14308\n",
      "processsed: 9000 rows out of 14308\n",
      "processsed: 9500 rows out of 14308\n",
      "processsed: 10000 rows out of 14308\n",
      "processsed: 10500 rows out of 14308\n",
      "processsed: 11000 rows out of 14308\n",
      "processsed: 11500 rows out of 14308\n",
      "processsed: 12000 rows out of 14308\n",
      "processsed: 12500 rows out of 14308\n",
      "processsed: 13000 rows out of 14308\n",
      "processsed: 13500 rows out of 14308\n",
      "processsed: 14000 rows out of 14308\n",
      "[['lie', 'floor', 'feather', 'find', 'hand', 'wanna', 'believe', 'not', 'think', 's', 'god', 'heaven', 'hell', 'lose', 'lookin', 'sign', 'maybe', 'fool', 'swear', 'spine', 'get', 'shiver', 'like', 'kiss', 'time', 'tho', 'tear', 'stream', 'like', 'river', 'know', 'ask', 'sign', 'scared', 'tho', 'body', 'start', 'shakin', 'feel', 'dry', 'eye', 'tho', 'heart', 'break', 'know', 'love', 'sign', 'sign', 'findin', 'street', 'starin', 'reach', 'turn', 'lookin', 'stranger', 'eye', 's', 'god', 'heaven', 'hell', 'tt', 'feel', 'like', 'walk', 'cos', 'touch', 'like', 'swear', 'spine', 'get', 'shiver', 'like', 'kiss', 'time', 'tho', 'tear', 'stream', 'like', 'river', 'know', 'ask', 'sign', 'scared', 'tho', 'body', 'start', 'shakin', 'feel', 'dry', 'eye', 'tho', 'heart', 'break', 'know', 'love', 'sign', 'sign', 'lie', 'floor', 'feather', 'find', 'hand', 'wanna', 'believe', 'not', 'think', 'swear', 'spine', 'get', 'shiver', 'like', 'kiss', 'time', 'tho', 'tear', 'stream', 'like', 'river', 'know', 'ask', 'sign', 'scared', 'tho', 'body', 'start', 'shakin', 'feel', 'dry', 'eye', 'tho', 'heart', 'break', 'know', 'love', 'sign', 'sign'], ['left', 'left', 'left', 'left', 'box', 'left', 'closet', 'yes', 'stuff', 'yes', 'buy', 'touch', 'talk', 'mess', 's', 'fine', 'walk', 'talk', 'time', 'and-', 's', 'tag', 'bag', 'let', 'cab', 'stand', 'yard', 'tell', 'fool', 'talk', \"'bout\", 'find', 'man', 'like', 'get', 'twist', 'know', 'know', 'minute', 'matter', 'fact', 'minute', 'know', 'know', 'tomorrow', 'second', 'thinkin', 'irreplaceable', 'ahead', 'grow', 'chick', 's', 'home', 'oop', 'bet', 'think', 'know', 'think', 'put', 'untrue', 'roll', 'car', 'buy', 'baby', 'drop', 'key', 'hurry', 'taxi', 'leave', 'stand', 'yard', 'tell', 'fool', 'talk', \"'bout\", 'find', 'man', 'like', 'get', 'twist', 'know', 'know', 'minute', 'matter', 'fact', 'minute', 'know', 'know', 'tomorrow', 'second', 'thinkin', 'irreplaceable', 'baby', 'will', 'shed', 'tear', 'will', 'lose', 'wink', 'sleep', 'cause', 'truth', 'matter', 'replace', 'easy', 'left', 'left', 'left', 'left', 'mmmmmmmm', 'left', 'left', 'box', 'left', 'left', 'left', 'second', 'think', 'irreplaceable', 'know', 'know', 'minute', 'matter', 'fact', 'minute', 'know', 'know', 'tomorrow', 'second', 'thinkin', 'know', 'know', 'minute', 'matter', 'fact', 'minute', 'pack', 'things-', 'finish', 'cause', 'bed', 'lie', 'tomorrow', 'second', 'thinkin', 'irreplaceable']]\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0   19    3   19   39   59\n",
      "    18  108  138    1  486   53   21    8  137   58 1100    8  143  101\n",
      "    63  137  116    2   75   20   23  322    9  440   21   23  294  322\n",
      "    23   79    2    1   11   23    1  212   14    9  440   21   23   79\n",
      "    53 1643   33   53 1643   33   10   22  285  323    5   23    4 1113\n",
      "    10  780   21  139    8  137 1364   58  323   61   15    7  137  169\n",
      "    75   20   23  322    9  440   21   23  294  322   23   79    2    1\n",
      "    11   23    1  212   14    9  440   21   23   79   53 1643   33   53\n",
      "  1643   33   76   19   95   39   34   16   46    4   13  323  440   21\n",
      "   105  646  399  120   15   15   23   12    9  440   21   23  294   12\n",
      "    23   79    2    1   11   23    1  212   14    9  440   21   23   79\n",
      "    53 1643   33   53 1643   33   53 1643   33   53 1643   33]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0   19   27    3   69    8   22 1317   50  125\n",
      "     3  481   23   15  125  125  577    4   10   81    5   25   93  143\n",
      "   540   18   10   22  125    3  481   23   15   35  125  125  577    4\n",
      "    10  179  545  171  179    1  545  171  125    3  481   23   15   35\n",
      "   125  125  577    4   10  179  545  171  179    1  545  171]]\n"
     ]
    }
   ],
   "source": [
    "word2vec_model_7,x_train, x_test, y_train, y_test = prepare_dataset(\"./data/song-data-labels-cleaned-seven-moods.csv\",7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a48e670a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7653/2941263412.py:44: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model_CV = KerasClassifier(build_fn=create_model, epochs=epochs,\n",
      "2023-03-07 10:43:08.096782: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:08.123395: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:08.125399: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:08.194583: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:08.212304: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:08.246827: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:08.292797: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:08.324042: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:08.324557: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-07 10:43:08.342628: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:08.342851: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-07 10:43:08.373875: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:08.374037: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-07 10:43:08.377663: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:08.400543: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:08.400714: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-07 10:43:08.436031: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:08.436177: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-07 10:43:08.460272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:08.460433: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-07 10:43:08.520441: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:08.520611: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-07 10:43:08.626253: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:08.626946: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-07 10:43:09.621078: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.621763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.621884: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-07 10:43:09.690380: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.690731: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.690920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-07 10:43:09.769019: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.769299: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.769441: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-07 10:43:09.790818: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.791296: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.791406: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 10:43:09.832460: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.833431: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.833570: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-07 10:43:09.879221: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.880120: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.881459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-07 10:43:09.954621: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.955248: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.955381: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-07 10:43:09.992591: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.992973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:09.993157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-07 10:43:11.391956: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-07 10:43:11.392581: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.392702: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.392853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.392986: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.393135: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.393267: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.393386: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.393503: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.393565: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-07 10:43:11.393955: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:11.540633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-07 10:43:11.541069: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.541222: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.541352: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.541440: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.541528: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.541616: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.541704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.541795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.541817: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-07 10:43:11.542177: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:11.590874: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-07 10:43:11.591380: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.591502: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.591567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.591627: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.591728: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.591793: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.591853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.591911: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.591927: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-07 10:43:11.592191: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 10:43:11.789830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-07 10:43:11.790647: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.790857: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.791149: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.791291: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.791400: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.791547: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.791677: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.791769: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.791820: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-07 10:43:11.792139: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:11.816378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-07 10:43:11.817055: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.817237: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.817328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.817410: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.817530: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.817663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.817850: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.817968: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.817995: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-07 10:43:11.818450: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:11.830683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-07 10:43:11.831153: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.831311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.831413: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.831493: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.831600: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.831684: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.831768: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.831849: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.831869: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-07 10:43:11.832178: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:11.914635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-07 10:43:11.915559: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.915807: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.915988: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.916126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.916277: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.916424: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.916583: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.916743: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.916800: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-07 10:43:11.917228: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-07 10:43:11.964260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-07 10:43:11.964928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.965124: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.965243: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.965343: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.965439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.965530: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.965628: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.965722: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-07 10:43:11.965745: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-07 10:43:11.966138: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "222/222 [==============================] - 126s 550ms/step - loss: 1.1264 - accuracy: 0.1466\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 126s 548ms/step - loss: 1.0365 - accuracy: 0.1439\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 129s 558ms/step - loss: 0.4226 - accuracy: 0.1418\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 129s 547ms/step - loss: 0.4223 - accuracy: 0.1443\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 140s 615ms/step - loss: 0.4213 - accuracy: 0.1466\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 141s 617ms/step - loss: 0.4203 - accuracy: 0.1428\n",
      "  2/222 [..............................] - ETA: 2:13 - loss: 0.4162 - accuracy: 0.0781Epoch 2/3\n",
      "222/222 [==============================] - 145s 614ms/step - loss: 0.5359 - accuracy: 0.1443\n",
      " 35/222 [===>..........................] - ETA: 1:43 - loss: 0.4150 - accuracy: 0.1473Epoch 2/3\n",
      "222/222 [==============================] - 147s 631ms/step - loss: 0.4822 - accuracy: 0.1409\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 129s 579ms/step - loss: 0.9384 - accuracy: 0.1514\n",
      "222/222 [==============================] - 125s 565ms/step - loss: 0.4106 - accuracy: 0.1742\n",
      "Epoch 3/3\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 129s 580ms/step - loss: 0.4138 - accuracy: 0.1478\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 129s 583ms/step - loss: 0.4140 - accuracy: 0.1515\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 143s 645ms/step - loss: 0.4138 - accuracy: 0.1525\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 145s 651ms/step - loss: 0.4093 - accuracy: 0.1834\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 146s 657ms/step - loss: 0.4113 - accuracy: 0.1659\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 145s 653ms/step - loss: 0.4124 - accuracy: 0.1514\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 133s 599ms/step - loss: 0.3945 - accuracy: 0.2340\n",
      "222/222 [==============================] - 135s 609ms/step - loss: 0.9371 - accuracy: 0.1665\n",
      "222/222 [==============================] - 135s 610ms/step - loss: 0.4122 - accuracy: 0.1550\n",
      "222/222 [==============================] - 133s 601ms/step - loss: 0.4042 - accuracy: 0.2105\n",
      "222/222 [==============================] - 21s 82ms/step - loss: 0.4109 - accuracy: 0.1961\n",
      "214/222 [===========================>..] - ETA: 4s - loss: 0.4060 - accuracy: 0.2043Epoch 1/3\n",
      "222/222 [==============================] - 133s 598ms/step - loss: 0.4060 - accuracy: 0.2049\n",
      "222/222 [==============================] - 131s 588ms/step - loss: 0.3942 - accuracy: 0.2477\n",
      "222/222 [==============================] - 127s 572ms/step - loss: 0.4086 - accuracy: 0.1973\n",
      "222/222 [==============================] - 127s 569ms/step - loss: 0.4102 - accuracy: 0.1639\n",
      "222/222 [==============================] - 7s 31ms/step - loss: 0.4092 - accuracy: 0.1769\n",
      " 79/222 [=========>....................] - ETA: 16s - loss: 2.1800 - accuracy: 0.1460Epoch 1/3\n",
      "222/222 [==============================] - 44s 163ms/step - loss: 2.1947 - accuracy: 0.1433\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 27s 115ms/step - loss: 0.4123 - accuracy: 0.1823\n",
      "222/222 [==============================] - 27s 114ms/step - loss: 0.9102 - accuracy: 0.1466\n",
      "222/222 [==============================] - 27s 114ms/step - loss: 0.3966 - accuracy: 0.2245\n",
      "222/222 [==============================] - 30s 128ms/step - loss: 0.3983 - accuracy: 0.2350\n",
      "222/222 [==============================] - 30s 130ms/step - loss: 0.3894 - accuracy: 0.2578\n",
      "178/222 [=======================>......] - ETA: 5s - loss: 0.4103 - accuracy: 0.1712Epoch 1/3\n",
      "180/222 [=======================>......] - ETA: 5s - loss: 0.4102 - accuracy: 0.1707Epoch 1/3\n",
      " 48/222 [=====>........................] - ETA: 1:20 - loss: 2.2036 - accuracy: 0.1426Epoch 1/3\n",
      "222/222 [==============================] - 29s 117ms/step - loss: 0.4101 - accuracy: 0.1734\n",
      " 14/222 [>.............................] - ETA: 1:15 - loss: 0.4681 - accuracy: 0.1161Epoch 1/3\n",
      " 15/222 [=>............................] - ETA: 1:13 - loss: 0.4476 - accuracy: 0.1271Epoch 1/3\n",
      " 15/222 [=>............................] - ETA: 1:52 - loss: 3.5298 - accuracy: 0.1229Epoch 1/3\n",
      "222/222 [==============================] - 84s 351ms/step - loss: 0.5900 - accuracy: 0.1426\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 104s 469ms/step - loss: 2.2446 - accuracy: 0.1442\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 140s 590ms/step - loss: 0.4208 - accuracy: 0.1502\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 141s 594ms/step - loss: 0.4192 - accuracy: 0.1413\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 167s 698ms/step - loss: 1.0854 - accuracy: 0.1447\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 146s 658ms/step - loss: 0.4123 - accuracy: 0.1556\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 195s 745ms/step - loss: 0.7638 - accuracy: 0.1418\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 199s 755ms/step - loss: 0.4210 - accuracy: 0.1391\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 204s 769ms/step - loss: 0.4187 - accuracy: 0.1460\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 155s 699ms/step - loss: 2.2029 - accuracy: 0.1426\n",
      "222/222 [==============================] - 151s 679ms/step - loss: 0.4129 - accuracy: 0.1511\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 152s 684ms/step - loss: 0.4129 - accuracy: 0.1662\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 41s 170ms/step - loss: 2.2036 - accuracy: 0.1433\n",
      "136/222 [=================>............] - ETA: 1:04 - loss: 0.4147 - accuracy: 0.1457Epoch 1/3\n",
      "222/222 [==============================] - 149s 670ms/step - loss: 0.4085 - accuracy: 0.1744\n",
      "222/222 [==============================] - 166s 746ms/step - loss: 0.6758 - accuracy: 0.1377\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 160s 721ms/step - loss: 0.6609 - accuracy: 0.1524\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 160s 718ms/step - loss: 0.4134 - accuracy: 0.1589\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 36s 145ms/step - loss: 0.4110 - accuracy: 0.1905\n",
      "222/222 [==============================] - 156s 702ms/step - loss: 0.4134 - accuracy: 0.1512\n",
      "Epoch 3/3\n",
      " 27/222 [==>...........................] - ETA: 4:10 - loss: 5.0984 - accuracy: 0.1609Epoch 1/3\n",
      "222/222 [==============================] - 150s 673ms/step - loss: 0.4014 - accuracy: 0.2213\n",
      "222/222 [==============================] - 150s 673ms/step - loss: 0.4015 - accuracy: 0.2286\n",
      "222/222 [==============================] - 40s 165ms/step - loss: 0.3943 - accuracy: 0.2364\n",
      "211/222 [===========================>..] - ETA: 1s - loss: 0.3931 - accuracy: 0.2276Epoch 1/3\n",
      "222/222 [==============================] - 43s 167ms/step - loss: 0.3932 - accuracy: 0.2259\n",
      "222/222 [==============================] - 167s 752ms/step - loss: 0.6750 - accuracy: 0.1353\n",
      "154/222 [===================>..........] - ETA: 54s - loss: 0.4066 - accuracy: 0.1958Epoch 1/3\n",
      "222/222 [==============================] - 164s 737ms/step - loss: 0.6594 - accuracy: 0.1504\n",
      "222/222 [==============================] - 163s 735ms/step - loss: 0.4016 - accuracy: 0.2167\n",
      "222/222 [==============================] - 37s 154ms/step - loss: 0.6605 - accuracy: 0.1418\n",
      "222/222 [==============================] - 161s 724ms/step - loss: 0.4045 - accuracy: 0.2035\n",
      " 37/222 [====>.........................] - ETA: 20s - loss: 0.3949 - accuracy: 0.2584Epoch 1/3\n",
      "222/222 [==============================] - 29s 123ms/step - loss: 0.3961 - accuracy: 0.2499\n",
      " 49/222 [=====>........................] - ETA: 2:43 - loss: 0.4432 - accuracy: 0.1295Epoch 1/3\n",
      "222/222 [==============================] - 31s 130ms/step - loss: 0.6716 - accuracy: 0.1653\n",
      "222/222 [==============================] - 32s 132ms/step - loss: 0.3896 - accuracy: 0.2602\n",
      " 48/222 [=====>........................] - ETA: 2:40 - loss: 0.4320 - accuracy: 0.1458Epoch 1/3\n",
      "194/222 [=========================>....] - ETA: 34s - loss: 3.3905 - accuracy: 0.1485Epoch 1/3\n",
      "222/222 [==============================] - 308s 1s/step - loss: 3.2440 - accuracy: 0.1476\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/222 [==============================] - 315s 1s/step - loss: 5.2728 - accuracy: 0.1419\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 300s 1s/step - loss: 0.4235 - accuracy: 0.1354\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 296s 1s/step - loss: 0.4201 - accuracy: 0.1421\n",
      "135/222 [=================>............] - ETA: 2:27 - loss: 2.8656 - accuracy: 0.1481Epoch 2/3\n",
      "222/222 [==============================] - 297s 1s/step - loss: 3.0727 - accuracy: 0.1425\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 409s 2s/step - loss: 2.6074 - accuracy: 0.1461\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 294s 1s/step - loss: 3.0785 - accuracy: 0.1494\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 427s 2s/step - loss: 3.7537 - accuracy: 0.1430\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 430s 2s/step - loss: 0.4190 - accuracy: 0.1426\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 442s 2s/step - loss: 0.4231 - accuracy: 0.1497\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 301s 1s/step - loss: 0.4123 - accuracy: 0.1665\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 304s 1s/step - loss: 0.4131 - accuracy: 0.1488\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 305s 1s/step - loss: 3.7577 - accuracy: 0.1440\n",
      "222/222 [==============================] - 305s 1s/step - loss: 2.2072 - accuracy: 0.1433\n",
      "222/222 [==============================] - 79s 336ms/step - loss: 3.7608 - accuracy: 0.1418\n",
      " 36/222 [===>..........................] - ETA: 54s - loss: 2.2036 - accuracy: 0.1476Epoch 1/3\n",
      "222/222 [==============================] - 405s 2s/step - loss: 2.2042 - accuracy: 0.1425\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 69s 301ms/step - loss: 2.2036 - accuracy: 0.1423\n",
      "205/222 [==========================>...] - ETA: 31s - loss: 2.5224 - accuracy: 0.1405Epoch 1/3\n",
      "222/222 [==============================] - 289s 1s/step - loss: 0.4020 - accuracy: 0.2128\n",
      "222/222 [==============================] - 284s 1s/step - loss: 0.4024 - accuracy: 0.2199\n",
      "222/222 [==============================] - 397s 2s/step - loss: 2.4054 - accuracy: 0.1418\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 393s 2s/step - loss: 0.4098 - accuracy: 0.1843\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 392s 2s/step - loss: 0.4133 - accuracy: 0.1598\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 70s 304ms/step - loss: 0.3944 - accuracy: 0.2419\n",
      "222/222 [==============================] - 72s 309ms/step - loss: 0.4063 - accuracy: 0.1563\n",
      " 82/222 [==========>...................] - ETA: 3:43 - loss: 2.1585 - accuracy: 0.1406Epoch 1/3\n",
      " 52/222 [======>.......................] - ETA: 4:33 - loss: 2.2305 - accuracy: 0.1352Epoch 1/3\n",
      "222/222 [==============================] - 400s 2s/step - loss: 1.8967 - accuracy: 0.1421\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 364s 2s/step - loss: 2.2042 - accuracy: 0.1423\n",
      "222/222 [==============================] - 373s 2s/step - loss: 0.8204 - accuracy: 0.1519\n",
      "222/222 [==============================] - 368s 2s/step - loss: 0.3952 - accuracy: 0.2423\n",
      "222/222 [==============================] - 404s 2s/step - loss: 2.2100 - accuracy: 0.1423\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 370s 2s/step - loss: 0.4017 - accuracy: 0.2191\n",
      "222/222 [==============================] - 72s 306ms/step - loss: 2.2036 - accuracy: 0.1433\n",
      "177/222 [======================>.......] - ETA: 1:16 - loss: 0.4214 - accuracy: 0.1446Epoch 1/3\n",
      "222/222 [==============================] - 386s 2s/step - loss: 0.4201 - accuracy: 0.1440\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 390s 2s/step - loss: 0.4232 - accuracy: 0.1398\n",
      "159/222 [====================>.........] - ETA: 21s - loss: 0.6664 - accuracy: 0.1327Epoch 2/3\n",
      "222/222 [==============================] - 79s 350ms/step - loss: 0.6687 - accuracy: 0.1368\n",
      "210/222 [===========================>..] - ETA: 4s - loss: 0.3932 - accuracy: 0.2470Epoch 1/3\n",
      "222/222 [==============================] - 81s 356ms/step - loss: 0.3933 - accuracy: 0.2448\n",
      " 99/222 [============>.................] - ETA: 2:51 - loss: 2.2036 - accuracy: 0.1439Epoch 1/3\n",
      "222/222 [==============================] - 82s 352ms/step - loss: 0.3928 - accuracy: 0.2465\n",
      " 47/222 [=====>........................] - ETA: 4:31 - loss: 0.4154 - accuracy: 0.1430Epoch 1/3\n",
      "222/222 [==============================] - 340s 2s/step - loss: 1.4323 - accuracy: 0.1469\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 354s 2s/step - loss: 2.2036 - accuracy: 0.1433\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 387s 2s/step - loss: 0.4131 - accuracy: 0.1556\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 391s 2s/step - loss: 0.4131 - accuracy: 0.1591\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 495s 2s/step - loss: 1.3123 - accuracy: 0.1484\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 528s 2s/step - loss: 2.1977 - accuracy: 0.1416\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 526s 2s/step - loss: 0.4236 - accuracy: 0.1453\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 406s 2s/step - loss: 1.2750 - accuracy: 0.1637\n",
      "222/222 [==============================] - 538s 2s/step - loss: 0.4194 - accuracy: 0.1436\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 399s 2s/step - loss: 2.2036 - accuracy: 0.1433\n",
      "222/222 [==============================] - 89s 376ms/step - loss: 0.9295 - accuracy: 0.1593\n",
      "222/222 [==============================] - 386s 2s/step - loss: 0.4030 - accuracy: 0.2190\n",
      "222/222 [==============================] - 381s 2s/step - loss: 0.4027 - accuracy: 0.2173\n",
      "222/222 [==============================] - 88s 362ms/step - loss: 2.2036 - accuracy: 0.1423\n",
      " 16/222 [=>............................] - ETA: 57s - loss: 0.3925 - accuracy: 0.2617Epoch 1/3\n",
      "111/222 [==============>...............] - ETA: 3:41 - loss: 2.2036 - accuracy: 0.1433Epoch 1/3\n",
      "222/222 [==============================] - 89s 386ms/step - loss: 0.3965 - accuracy: 0.2220\n",
      "222/222 [==============================] - 462s 2s/step - loss: 0.9306 - accuracy: 0.1493\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 97s 420ms/step - loss: 0.3943 - accuracy: 0.2367\n",
      "164/222 [=====================>........] - ETA: 1:57 - loss: 2.2036 - accuracy: 0.1410Epoch 1/3\n",
      "222/222 [==============================] - 136s 512ms/step - loss: 1.9964 - accuracy: 0.1435\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 138s 521ms/step - loss: 0.8992 - accuracy: 0.1415\n",
      " 18/222 [=>............................] - ETA: 6:16 - loss: 0.8795 - accuracy: 0.1736Epoch 2/3\n",
      "  4/222 [..............................] - ETA: 1:45 - loss: 0.4118 - accuracy: 0.1172Epoch 1/3\n",
      "222/222 [==============================] - 529s 2s/step - loss: 2.2036 - accuracy: 0.1433\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 528s 2s/step - loss: 0.4144 - accuracy: 0.1429\n",
      "  2/222 [..............................] - ETA: 10:51 - loss: 2.2036 - accuracy: 0.1094Epoch 3/3\n",
      "222/222 [==============================] - 206s 797ms/step - loss: 0.4227 - accuracy: 0.1428\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 236s 1s/step - loss: 0.4128 - accuracy: 0.1509\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 242s 1s/step - loss: 1.1809 - accuracy: 0.1408\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 571s 3s/step - loss: 0.4137 - accuracy: 0.1504\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 286s 1s/step - loss: 0.4273 - accuracy: 0.1363\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 168s 757ms/step - loss: 0.4156 - accuracy: 0.1493\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 191s 861ms/step - loss: 1.1158 - accuracy: 0.1550\n",
      "222/222 [==============================] - 238s 1s/step - loss: 0.4102 - accuracy: 0.1762\n",
      "222/222 [==============================] - 36s 148ms/step - loss: 0.4051 - accuracy: 0.1915\n",
      "222/222 [==============================] - 235s 1s/step - loss: 0.4163 - accuracy: 0.1536\n",
      "Epoch 3/3\n",
      " 97/222 [============>.................] - ETA: 39s - loss: 0.9116 - accuracy: 0.1418Epoch 1/3\n",
      "222/222 [==============================] - 48s 204ms/step - loss: 0.9264 - accuracy: 0.1498\n",
      "222/222 [==============================] - 222s 980ms/step - loss: 0.4058 - accuracy: 0.2052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 66/222 [=======>......................] - ETA: 1:16 - loss: 1.0378 - accuracy: 0.1312Epoch 1/3\n",
      "222/222 [==============================] - 110s 496ms/step - loss: 0.4069 - accuracy: 0.1973\n",
      "222/222 [==============================] - 32s 132ms/step - loss: 0.3957 - accuracy: 0.2436\n",
      " 82/222 [==========>...................] - ETA: 1:25 - loss: 2.3745 - accuracy: 0.1444Epoch 1/3\n",
      "222/222 [==============================] - 32s 128ms/step - loss: 0.3978 - accuracy: 0.2015\n",
      "101/222 [============>.................] - ETA: 1:13 - loss: 2.3424 - accuracy: 0.1439Epoch 1/3\n",
      "222/222 [==============================] - 148s 548ms/step - loss: 0.7949 - accuracy: 0.1382\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 715s 3s/step - loss: 0.7065 - accuracy: 0.1464\n",
      "222/222 [==============================] - 175s 669ms/step - loss: 2.2660 - accuracy: 0.1423\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 648s 3s/step - loss: 0.4132 - accuracy: 0.1483\n",
      "222/222 [==============================] - 154s 694ms/step - loss: 0.5171 - accuracy: 0.1439\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 662s 3s/step - loss: 2.2036 - accuracy: 0.1433\n",
      "222/222 [==============================] - 140s 604ms/step - loss: 0.6654 - accuracy: 0.1408\n",
      "222/222 [==============================] - 185s 701ms/step - loss: 0.4236 - accuracy: 0.1478\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 187s 713ms/step - loss: 0.4240 - accuracy: 0.1543\n",
      "Epoch 2/3\n",
      " 70/222 [========>.....................] - ETA: 1:17 - loss: 0.4129 - accuracy: 0.1317Epoch 1/3\n",
      "222/222 [==============================] - 629s 3s/step - loss: 0.4135 - accuracy: 0.1409\n",
      "222/222 [==============================] - 138s 624ms/step - loss: 2.2031 - accuracy: 0.1429\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 109s 466ms/step - loss: 2.2036 - accuracy: 0.1423\n",
      "222/222 [==============================] - 125s 562ms/step - loss: 0.4122 - accuracy: 0.1416\n",
      "222/222 [==============================] - 108s 462ms/step - loss: 0.4086 - accuracy: 0.1913\n",
      "222/222 [==============================] - 122s 549ms/step - loss: 0.4150 - accuracy: 0.1583\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 119s 537ms/step - loss: 0.4117 - accuracy: 0.1766\n",
      "Epoch 3/3\n",
      "173/222 [======================>.......] - ETA: 26s - loss: 0.8362 - accuracy: 0.1472Epoch 1/3\n",
      " 25/222 [==>...........................] - ETA: 25s - loss: 0.4106 - accuracy: 0.1450Epoch 1/3\n",
      "222/222 [==============================] - 143s 523ms/step - loss: 0.7443 - accuracy: 0.1447\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 96s 400ms/step - loss: 0.4106 - accuracy: 0.1423\n",
      "222/222 [==============================] - 115s 516ms/step - loss: 2.2036 - accuracy: 0.1432\n",
      "222/222 [==============================] - 28s 119ms/step - loss: 0.4105 - accuracy: 0.1418\n",
      "222/222 [==============================] - 27s 109ms/step - loss: 2.2036 - accuracy: 0.1423\n",
      " 71/222 [========>.....................] - ETA: 1:12 - loss: 0.4142 - accuracy: 0.1422Epoch 1/3\n",
      " 78/222 [=========>....................] - ETA: 1:08 - loss: 3.1128 - accuracy: 0.1366Epoch 1/3\n",
      "119/222 [===============>..............] - ETA: 48s - loss: 2.7956 - accuracy: 0.1408Epoch 1/3\n",
      "222/222 [==============================] - 100s 452ms/step - loss: 0.4062 - accuracy: 0.2129\n",
      "222/222 [==============================] - 114s 515ms/step - loss: 0.3998 - accuracy: 0.2191\n",
      "222/222 [==============================] - 37s 154ms/step - loss: 0.3971 - accuracy: 0.2331\n",
      " 45/222 [=====>........................] - ETA: 2:01 - loss: 1.4838 - accuracy: 0.1299Epoch 1/3\n",
      "222/222 [==============================] - 145s 543ms/step - loss: 2.5169 - accuracy: 0.1460\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 123s 553ms/step - loss: 0.4133 - accuracy: 0.1450\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 157s 582ms/step - loss: 0.4225 - accuracy: 0.1411\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 39s 160ms/step - loss: 0.3938 - accuracy: 0.2516\n",
      "110/222 [=============>................] - ETA: 1:11 - loss: 0.4127 - accuracy: 0.1452Epoch 1/3\n",
      "222/222 [==============================] - 169s 640ms/step - loss: 0.4265 - accuracy: 0.1421\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 183s 710ms/step - loss: 0.7565 - accuracy: 0.1405\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 173s 699ms/step - loss: 1.2654 - accuracy: 0.1346\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 146s 660ms/step - loss: 2.2024 - accuracy: 0.1433\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 146s 659ms/step - loss: 0.4123 - accuracy: 0.1501\n",
      "222/222 [==============================] - 150s 674ms/step - loss: 0.4150 - accuracy: 0.1538\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 194s 737ms/step - loss: 0.4263 - accuracy: 0.1428\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 153s 690ms/step - loss: 0.4135 - accuracy: 0.1675\n",
      "166/222 [=====================>........] - ETA: 8s - loss: 0.4100 - accuracy: 0.1755Epoch 3/3\n",
      "222/222 [==============================] - 40s 162ms/step - loss: 0.4100 - accuracy: 0.1714\n",
      "214/222 [===========================>..] - ETA: 5s - loss: 0.4137 - accuracy: 0.1500Epoch 1/3\n",
      "222/222 [==============================] - 160s 722ms/step - loss: 0.4137 - accuracy: 0.1494\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 165s 743ms/step - loss: 0.8022 - accuracy: 0.1453\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 204s 757ms/step - loss: 0.4267 - accuracy: 0.1384\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 147s 661ms/step - loss: 2.2009 - accuracy: 0.1436\n",
      "222/222 [==============================] - 142s 641ms/step - loss: 0.4099 - accuracy: 0.1872\n",
      "222/222 [==============================] - 157s 707ms/step - loss: 0.4105 - accuracy: 0.1892\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 36s 151ms/step - loss: 2.2036 - accuracy: 0.1423\n",
      "128/222 [================>.............] - ETA: 14s - loss: 0.4035 - accuracy: 0.2090Epoch 1/3\n",
      "222/222 [==============================] - 143s 643ms/step - loss: 0.3978 - accuracy: 0.2261\n",
      "222/222 [==============================] - 37s 152ms/step - loss: 0.4033 - accuracy: 0.2063\n",
      "190/222 [========================>.....] - ETA: 21s - loss: 0.4120 - accuracy: 0.1518Epoch 1/3\n",
      "222/222 [==============================] - 150s 676ms/step - loss: 0.4121 - accuracy: 0.1504\n",
      "222/222 [==============================] - 36s 151ms/step - loss: 0.3938 - accuracy: 0.2415\n",
      "222/222 [==============================] - 150s 674ms/step - loss: 0.4193 - accuracy: 0.1488\n",
      "222/222 [==============================] - 152s 686ms/step - loss: 0.4149 - accuracy: 0.1697\n",
      "Epoch 3/3\n",
      "147/222 [==================>...........] - ETA: 48s - loss: 0.3979 - accuracy: 0.2349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/venv/ta_3.10/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/222 [====================>.........] - ETA: 42s - loss: 0.3977 - accuracy: 0.2363"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 12:03:56.141176: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21/222 [=>............................] - ETA: 1:56 - loss: 0.4054 - accuracy: 0.2009"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 12:03:57.338852: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 12:03:57.354728: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7/222 [..............................] - ETA: 27s - loss: 0.4097 - accuracy: 0.1652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 12:04:05.286782: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 12:04:05.288552: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-07 12:04:05.288920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58/222 [======>.......................] - ETA: 1:31 - loss: 0.4059 - accuracy: 0.1983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 12:04:17.601067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-07 12:04:17.603809: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-07 12:04:17.603983: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 12:04:17.604094: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 12:04:17.604197: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 12:04:17.604297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-03-07 12:04:17.604443: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 12:04:17.604588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-03-07 12:04:17.604720: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-03-07 12:04:17.604750: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-03-07 12:04:17.605590: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/222 [===============>..............] - ETA: 15s - loss: 0.4109 - accuracy: 0.1440Epoch 1/3\n",
      "222/222 [==============================] - 139s 625ms/step - loss: 0.3956 - accuracy: 0.2437\n",
      "222/222 [==============================] - 36s 150ms/step - loss: 0.4110 - accuracy: 0.1435\n",
      "222/222 [==============================] - 34s 138ms/step - loss: 0.4110 - accuracy: 0.1413\n",
      "116/222 [==============>...............] - ETA: 57s - loss: 0.4046 - accuracy: 0.2029Epoch 1/3\n",
      "118/222 [==============>...............] - ETA: 56s - loss: 0.4046 - accuracy: 0.2031Epoch 1/3\n",
      "222/222 [==============================] - 301s 1s/step - loss: 1.6896 - accuracy: 0.1361\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 130s 588ms/step - loss: 0.4013 - accuracy: 0.2160\n",
      "222/222 [==============================] - 49s 201ms/step - loss: 0.3954 - accuracy: 0.2436\n",
      " 49/222 [=====>........................] - ETA: 3:00 - loss: 0.6971 - accuracy: 0.1448Epoch 1/3\n",
      "222/222 [==============================] - 299s 1s/step - loss: 0.7422 - accuracy: 0.1445\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 57s 240ms/step - loss: 0.3947 - accuracy: 0.2440\n",
      "222/222 [==============================] - 292s 1s/step - loss: 0.4273 - accuracy: 0.1452\n",
      "Epoch 2/3\n",
      " 23/222 [==>...........................] - ETA: 4:01 - loss: 0.4169 - accuracy: 0.1372Epoch 1/3\n",
      "222/222 [==============================] - 324s 1s/step - loss: 0.4288 - accuracy: 0.1457\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 300s 1s/step - loss: 0.5147 - accuracy: 0.1437\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 430s 2s/step - loss: 1.5341 - accuracy: 0.1402\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 437s 2s/step - loss: 1.0111 - accuracy: 0.1457\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 294s 1s/step - loss: 0.4130 - accuracy: 0.1412\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 292s 1s/step - loss: 0.4165 - accuracy: 0.1507\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 440s 2s/step - loss: 0.4252 - accuracy: 0.1477\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 294s 1s/step - loss: 0.4135 - accuracy: 0.1675\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 291s 1s/step - loss: 0.4128 - accuracy: 0.1425\n",
      "222/222 [==============================] - 439s 2s/step - loss: 0.4231 - accuracy: 0.1388\n",
      "141/222 [==================>...........] - ETA: 1:49 - loss: 0.4125 - accuracy: 0.1432Epoch 2/3\n",
      "222/222 [==============================] - 76s 326ms/step - loss: 0.4104 - accuracy: 0.1391\n",
      "107/222 [=============>................] - ETA: 3:23 - loss: 0.4176 - accuracy: 0.1440Epoch 1/3\n",
      "222/222 [==============================] - 293s 1s/step - loss: 0.4122 - accuracy: 0.1452\n",
      "222/222 [==============================] - 292s 1s/step - loss: 0.4075 - accuracy: 0.2016\n",
      "222/222 [==============================] - 378s 2s/step - loss: 0.4138 - accuracy: 0.1528\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 392s 2s/step - loss: 0.4145 - accuracy: 0.1546\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 76s 331ms/step - loss: 0.4103 - accuracy: 0.1413\n",
      "172/222 [======================>.......] - ETA: 1:27 - loss: 0.4174 - accuracy: 0.1475Epoch 1/3\n",
      "222/222 [==============================] - 73s 313ms/step - loss: 0.3973 - accuracy: 0.2326\n",
      "222/222 [==============================] - 283s 1s/step - loss: 0.4025 - accuracy: 0.2131\n",
      "131/222 [================>.............] - ETA: 2:33 - loss: 0.4168 - accuracy: 0.1431Epoch 1/3\n",
      "222/222 [==============================] - 381s 2s/step - loss: 0.4162 - accuracy: 0.1557\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 73s 317ms/step - loss: 0.3976 - accuracy: 0.2218\n",
      " 48/222 [=====>........................] - ETA: 4:57 - loss: 1.9121 - accuracy: 0.1589Epoch 1/3\n",
      "222/222 [==============================] - 371s 2s/step - loss: 0.4159 - accuracy: 0.1487\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 415s 2s/step - loss: 2.2463 - accuracy: 0.1418\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 381s 2s/step - loss: 0.4125 - accuracy: 0.1473\n",
      "222/222 [==============================] - 385s 2s/step - loss: 0.4100 - accuracy: 0.1738\n",
      "222/222 [==============================] - 414s 2s/step - loss: 1.5387 - accuracy: 0.1512\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 424s 2s/step - loss: 0.4277 - accuracy: 0.1422\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 386s 2s/step - loss: 0.4026 - accuracy: 0.2175\n",
      "222/222 [==============================] - 87s 377ms/step - loss: 0.4105 - accuracy: 0.1418\n",
      "222/222 [==============================] - 88s 383ms/step - loss: 0.4042 - accuracy: 0.2077\n",
      "106/222 [=============>................] - ETA: 3:16 - loss: 2.2036 - accuracy: 0.1448Epoch 1/3\n",
      "222/222 [==============================] - 415s 2s/step - loss: 0.4265 - accuracy: 0.1433\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 362s 2s/step - loss: 0.4129 - accuracy: 0.1621\n",
      " 56/222 [======>.......................] - ETA: 52s - loss: 0.3881 - accuracy: 0.2573Epoch 1/3\n",
      "222/222 [==============================] - 83s 361ms/step - loss: 0.3897 - accuracy: 0.2491\n",
      "222/222 [==============================] - 79s 344ms/step - loss: 0.4063 - accuracy: 0.1774\n",
      " 54/222 [======>.......................] - ETA: 5:27 - loss: 2.2101 - accuracy: 0.1418Epoch 1/3\n",
      "130/222 [================>.............] - ETA: 2:21 - loss: 0.8370 - accuracy: 0.1457Epoch 1/3\n",
      "222/222 [==============================] - 348s 2s/step - loss: 2.2036 - accuracy: 0.1423\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 360s 2s/step - loss: 0.7689 - accuracy: 0.1469\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 355s 2s/step - loss: 0.4165 - accuracy: 0.1425\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 385s 2s/step - loss: 0.4146 - accuracy: 0.1625\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 503s 2s/step - loss: 2.2052 - accuracy: 0.1418\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 415s 2s/step - loss: 2.2036 - accuracy: 0.1422\n",
      "222/222 [==============================] - 534s 2s/step - loss: 0.9765 - accuracy: 0.1474\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 544s 2s/step - loss: 0.4253 - accuracy: 0.1440\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 544s 2s/step - loss: 0.4242 - accuracy: 0.1443\n",
      "Epoch 2/3\n",
      "222/222 [==============================] - 97s 421ms/step - loss: 2.2036 - accuracy: 0.1433\n",
      "222/222 [==============================] - 409s 2s/step - loss: 0.5046 - accuracy: 0.1429\n",
      "222/222 [==============================] - 411s 2s/step - loss: 0.4087 - accuracy: 0.1895\n",
      "222/222 [==============================] - 84s 362ms/step - loss: 0.4104 - accuracy: 0.1368\n",
      "222/222 [==============================] - 80s 345ms/step - loss: 0.4010 - accuracy: 0.2417\n",
      "222/222 [==============================] - 393s 2s/step - loss: 0.3985 - accuracy: 0.2245\n",
      "222/222 [==============================] - 56s 243ms/step - loss: 0.3928 - accuracy: 0.2352\n",
      "222/222 [==============================] - 401s 2s/step - loss: 2.2036 - accuracy: 0.1422\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 357s 2s/step - loss: 0.4142 - accuracy: 0.1405\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 318s 1s/step - loss: 0.4157 - accuracy: 0.1539\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 317s 1s/step - loss: 0.4158 - accuracy: 0.1470\n",
      "Epoch 3/3\n",
      "222/222 [==============================] - 247s 1s/step - loss: 2.2036 - accuracy: 0.1423\n",
      "222/222 [==============================] - 238s 1s/step - loss: 0.4127 - accuracy: 0.1447\n",
      "222/222 [==============================] - 232s 1s/step - loss: 0.4065 - accuracy: 0.2025\n",
      "222/222 [==============================] - 233s 1s/step - loss: 0.4094 - accuracy: 0.1802\n",
      "222/222 [==============================] - 43s 187ms/step - loss: 2.2036 - accuracy: 0.1433\n",
      "222/222 [==============================] - 38s 169ms/step - loss: 0.4105 - accuracy: 0.1423\n",
      "156/222 [====================>.........] - ETA: 4s - loss: 0.3957 - accuracy: 0.2352"
     ]
    }
   ],
   "source": [
    "test_dataset(word2vec_model_7,x_train, x_test, y_train, y_test, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b6653",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model_17,x_train, x_test, y_train, y_test = prepare_dataset(\"./data/song-data-labels-cleaned.csv\",17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d50991",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset(word2vec_model_17,x_train, x_test, y_train, y_test, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7037706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model_4,x_train, x_test, y_train, y_test = prepare_dataset(\"./data/song-data-labels-cleaned-quadrant.csv\",4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c4a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset(word2vec_model_4,x_train, x_test, y_train, y_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c564ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = create_model(200, word2vec_model_17,7, 50, 2, 4, 5, \"softmax\")\n",
    "plot_model(\n",
    "    keras_model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd64d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ta_3.10",
   "language": "python",
   "name": "ta_3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc1f558fa75d74d13a110a756bf00a1a7a77d8327c013f6ebbe6af7a56ad119a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
