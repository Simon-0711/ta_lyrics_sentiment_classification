{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7027cc2",
   "metadata": {},
   "source": [
    "## This notebook was for the first cut solution of a CNN + for evaluating the different dataset we generated from our data in accordance with the CNN predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43598701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 08:50:25.357371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-28 08:50:25.871517: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-28 08:50:25.871568: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-28 08:50:27.271811: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-28 08:50:27.271970: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-28 08:50:27.271982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Embedding,GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Conv1D, MaxPool1D, GlobalMaxPool1D, Embedding, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Preprocessing and model is used from \n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2446eea8",
   "metadata": {},
   "source": [
    "## Adapt the preprocessing pipeline to the songs so thath the input is cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0cdeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 08:50:30.059343: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-28 08:50:30.059857: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-28 08:50:30.059890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def tokenization(text):\n",
    "    \"\"\"Use this function to tokenize text.\n",
    "\n",
    "    :param text: Text as list\n",
    "    :type text: list[spacy.tokens.token.Token]\n",
    "    :return: Tokenized text as list\n",
    "    :rtype: list[spacy.tokens.token.Token]\n",
    "    \"\"\"\n",
    "\n",
    "    token_list = []\n",
    "    for doc in text: \n",
    "        # iterate over tokens in docs\n",
    "        for token in doc:\n",
    "            token_list.append(token)\n",
    "\n",
    "    return token_list\n",
    "\n",
    "\n",
    "def stop_word_removal(text): \n",
    "    \"\"\"Use this function to remove stop words. \n",
    "\n",
    "    :param text: Tokens to remove stop words from \n",
    "    :type text: list[spacy.tokens.token.Token]\n",
    "    :return: Tokens without stop words\n",
    "    :rtype: list[spacy.tokens.token.Token]\n",
    "    \"\"\"\n",
    "\n",
    "    token_list_without_stop = []\n",
    "    # Don't add token to list if stop word\n",
    "    for token in text:\n",
    "        if token.is_stop == False: \n",
    "            token_list_without_stop.append(token)\n",
    "\n",
    "    return token_list_without_stop\n",
    "\n",
    "\n",
    "def punctutation_removal(text): \n",
    "    \"\"\"Use this function to remove punctuation.\n",
    "\n",
    "    :param text: Tokens to remove punctuation from\n",
    "    :type text: list[spacy.tokens.token.Token]\n",
    "    :return: Tokens without punctuation\n",
    "    :rtype: list[spacy.tokens.token.Token]\n",
    "    \"\"\"\n",
    "\n",
    "    token_list_no_stop_no_punct = []\n",
    "    # Don't add token to list if punctuation\n",
    "    for token in text:\n",
    "        if token.is_punct == False:\n",
    "            token_list_no_stop_no_punct.append(token)\n",
    "\n",
    "    return token_list_no_stop_no_punct\n",
    "\n",
    "\n",
    "def lemmatization(text): \n",
    "    \"\"\"Use this function to lemmatize a given text.\n",
    "\n",
    "    :param text: Tokens to lemmatize\n",
    "    :type text: list[spacy.tokens.token.Token]\n",
    "    :return: lemmatized tokens\n",
    "    :rtype: list[str]\n",
    "    \"\"\"\n",
    "\n",
    "    token_list_no_stop_no_punct_lemmatized = []\n",
    "    for token in text: \n",
    "        if \"\\n\" not in token.lemma_:\n",
    "            token_list_no_stop_no_punct_lemmatized.append(token.lemma_)\n",
    "    return token_list_no_stop_no_punct_lemmatized\n",
    "\n",
    "\n",
    "def processing_pipeline(song_data):\n",
    "    \"\"\"Use this function to execute the entire processing pipeline on given song data.\n",
    "    Preprocessing steps:\n",
    "    - Tokenization\n",
    "    - Stop word removal\n",
    "    - Punctuation removal\n",
    "    - Lemmatization\n",
    "    - ...\n",
    "\n",
    "    :param song_data: song data saved in a json file containing song name, artist name and lyrics\n",
    "    :type song_data: dict\n",
    "    :return: preprocessed song data\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable = ['ner'])\n",
    "    \n",
    "    for row in range(len(song_data)):\n",
    "        text_nlp_pipe = list(nlp.pipe([song_data.iloc[row][\"Lyric\"]]))\n",
    "    \n",
    "        # Tokenization\n",
    "        song_data.at[row,\"Lyric\"] = tokenization(text_nlp_pipe)\n",
    "        # Stop word removal\n",
    "        song_data.at[row,\"Lyric\"] = stop_word_removal(song_data.iloc[row][\"Lyric\"])\n",
    "        # Punctuation removal\n",
    "        song_data.at[row,\"Lyric\"] = punctutation_removal(song_data.iloc[row][\"Lyric\"])\n",
    "        # Lemmatization\n",
    "        song_data.at[row,\"Lyric\"] = lemmatization(song_data.iloc[row][\"Lyric\"])\n",
    "        song_data.at[row,\"Lyric\"] = \" \".join(song_data.iloc[row][\"Lyric\"])\n",
    "        song_data.at[row,\"Lyric\"] = song_data.iloc[row][\"Lyric\"].lower()\n",
    "        if row%500 == 0 and row >= 500:\n",
    "            print(f\"processsed: {row} rows out of {len(song_data)}\")\n",
    "    return song_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f400ebb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to use the word2vec as an layer in keras \n",
    "# taken from the gensim wikipage: https://github.com/RaRe-Technologies/gensim/wiki/Using-Gensim-Embeddings-with-Keras-and-Tensorflow\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def gensim_to_keras_embedding(model, train_embeddings=False):\n",
    "    \"\"\"Get a Keras 'Embedding' layer with weights set from Word2Vec model's learned word embeddings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_embeddings : bool\n",
    "        If False, the returned weights are frozen and stopped from being updated.\n",
    "        If True, the weights can / will be further updated in Keras.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    `keras.layers.Embedding`\n",
    "        Embedding layer, to be used as input to deeper network layers.\n",
    "\n",
    "    \"\"\"\n",
    "    keyed_vectors = model.wv  # structure holding the result of training\n",
    "    weights = keyed_vectors.vectors  # vectors themselves, a 2D numpy array    \n",
    "    index_to_key = keyed_vectors.index_to_key  # which row in `weights` corresponds to which word?\n",
    "\n",
    "    layer = Embedding(\n",
    "        input_dim=weights.shape[0],\n",
    "        output_dim=weights.shape[1],\n",
    "        weights=[weights],\n",
    "        trainable=train_embeddings,\n",
    "    )\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb8a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(density, wrd2vecmodel,mood_count,filters,multiplicator, multiplicator2, kernel, adapt_embedding, outputfunction):\n",
    "    \n",
    "    keras_model = Sequential()\n",
    "    keras_model.add(gensim_to_keras_embedding(wrd2vecmodel, True))\n",
    "    keras_model.add(Dropout(0.2))\n",
    "    keras_model.add(Conv1D(filters, kernel, activation='relu', padding='same', strides=1))\n",
    "    keras_model.add(Conv1D(filters, kernel, activation='relu', padding='same', strides=1))\n",
    "    keras_model.add(MaxPool1D())\n",
    "    keras_model.add(Dropout(0.2))\n",
    "    keras_model.add(Conv1D(filters*multiplicator, kernel, activation='relu', padding='same', strides=1))\n",
    "    keras_model.add(Conv1D(filters*multiplicator, kernel, activation='relu', padding='same', strides=1))\n",
    "    keras_model.add(MaxPool1D())\n",
    "    keras_model.add(Dropout(0.2))\n",
    "    keras_model.add(Conv1D(filters*multiplicator2, kernel, activation='relu', padding='same', strides=1))\n",
    "    keras_model.add(Conv1D(filters*multiplicator2, kernel, activation='relu', padding='same', strides=1))\n",
    "    keras_model.add(GlobalMaxPool1D())\n",
    "    keras_model.add(Dropout(0.2))\n",
    "    keras_model.add(Dense(density))\n",
    "    keras_model.add(Activation('relu'))\n",
    "    keras_model.add(Dropout(0.2))\n",
    "    # Number of moods to be classified to\n",
    "    keras_model.add(Dense(mood_count))\n",
    "    keras_model.add(Activation(outputfunction))\n",
    "    \n",
    "    keras_model.compile(loss='binary_crossentropy', metrics=['acc'], optimizer='adam')\n",
    "    return keras_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad98c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dataset(dataset_path, mood_count):\n",
    "    print(f\"Testing now dataset {dataset_path} with {mood_count} moods\")\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print((df[\"Mood\"].unique()))\n",
    "    df = processing_pipeline(df)\n",
    "    list(df[\"Lyric\"].head(2))\n",
    "    # merge lyrics together\n",
    "    lyrics = []\n",
    "    for i in df['Lyric']:\n",
    "        lyrics.append(i.split())\n",
    "    print(lyrics[:2])\n",
    "    \n",
    "    # train the word2vec model\n",
    "    # vector size according to https://moj-analytical-services.github.io/NLP-guidance/NNmodels.html#:~:text=The%20standard%20Word2Vec%20pre%2Dtrained,fewer%20dimensions%20to%20represent%20them.\n",
    "    # mincount = 2 to prevent misspellings\n",
    "    word2vec_model = Word2Vec(lyrics, vector_size=150, window=5, min_count=2, workers=16)\n",
    "    \n",
    "    # use the keras tokenizer and apply it to the lyrics\n",
    "    # number in first row is vocab size from word2vec model\n",
    "    token = Tokenizer(len(word2vec_model.wv))\n",
    "    token.fit_on_texts(df['Lyric'])\n",
    "    text = token.texts_to_sequences(df['Lyric'])\n",
    "    text = pad_sequences(text, 180)\n",
    "    print(text[3:5])\n",
    "    \n",
    "    # encode the labels\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    y = le.fit_transform(df['Mood'])\n",
    "    y = to_categorical(y)\n",
    "    # save the label encoder\n",
    "    np.save('data/label_encoder.npy', le.classes_)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(np.array(text), y, test_size=0.2, stratify=y)\n",
    "    \n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    batch_size = 32\n",
    "    epochs = 3\n",
    "\n",
    "    model_CV = KerasClassifier(build_fn=create_model, epochs=epochs, \n",
    "                               batch_size=batch_size, verbose=1)\n",
    "    # grid search parameters\n",
    "    filters = [50, 100]\n",
    "    multiplicator = [2]\n",
    "    multiplicator2 = [3,4]\n",
    "    kernel = [5]\n",
    "    adapt_embedding = [True, False]\n",
    "    outputfunction = [\"relu\",\"softmax\"]\n",
    "    word2vecmodel = [word2vec_model]\n",
    "    density = [200, 50]\n",
    "\n",
    "    param_grid = dict(density, wrd2vecmodel=word2vecmodel,mood_count=[mood_count], filters=filters, multiplicator=multiplicator, multiplicator2=multiplicator2, kernel=kernel, adapt_embedding=adapt_embedding, outputfunction=outputfunction)\n",
    "    grid = GridSearchCV(estimator=model_CV, param_grid=param_grid, n_jobs=-1, cv=2)\n",
    "    grid_result = grid.fit(x_train, y_train)\n",
    "    \n",
    "    \n",
    "    # print results\n",
    "    print(f'Best Accuracy for dataset {dataset_path} is: {grid_result.best_score_} using {grid_result.best_params_}')\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(f' mean={mean:.4}, std={stdev:.4} using {param}')\n",
    "    print(\"##\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462d19d3",
   "metadata": {},
   "source": [
    "## Test the dataset with unnormalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe3da31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing now dataset ./data/song-data-labels-cleaned.csv with 17 moods\n",
      "['romantic' 'happy' 'sad' 'grief' 'upbeat' 'earnest' 'cheerful'\n",
      " 'depressed' 'anger' 'calm' 'excitement' 'aggression' 'confident' 'angst'\n",
      " 'brooding' 'desire' 'pessimism']\n",
      "processsed: 500 rows out of 27705\n",
      "processsed: 1000 rows out of 27705\n",
      "processsed: 1500 rows out of 27705\n",
      "processsed: 2000 rows out of 27705\n",
      "processsed: 2500 rows out of 27705\n",
      "processsed: 3000 rows out of 27705\n",
      "processsed: 3500 rows out of 27705\n",
      "processsed: 4000 rows out of 27705\n",
      "processsed: 4500 rows out of 27705\n",
      "processsed: 5000 rows out of 27705\n",
      "processsed: 5500 rows out of 27705\n",
      "processsed: 6000 rows out of 27705\n",
      "processsed: 6500 rows out of 27705\n",
      "processsed: 7000 rows out of 27705\n",
      "processsed: 7500 rows out of 27705\n",
      "processsed: 8000 rows out of 27705\n",
      "processsed: 8500 rows out of 27705\n",
      "processsed: 9000 rows out of 27705\n",
      "processsed: 9500 rows out of 27705\n",
      "processsed: 10000 rows out of 27705\n",
      "processsed: 10500 rows out of 27705\n",
      "processsed: 11000 rows out of 27705\n",
      "processsed: 11500 rows out of 27705\n",
      "processsed: 12000 rows out of 27705\n",
      "processsed: 12500 rows out of 27705\n",
      "processsed: 13000 rows out of 27705\n",
      "processsed: 13500 rows out of 27705\n",
      "processsed: 14000 rows out of 27705\n",
      "processsed: 14500 rows out of 27705\n",
      "processsed: 15000 rows out of 27705\n",
      "processsed: 15500 rows out of 27705\n",
      "processsed: 16000 rows out of 27705\n",
      "processsed: 16500 rows out of 27705\n",
      "processsed: 17000 rows out of 27705\n",
      "processsed: 17500 rows out of 27705\n",
      "processsed: 18000 rows out of 27705\n",
      "processsed: 18500 rows out of 27705\n",
      "processsed: 19000 rows out of 27705\n",
      "processsed: 19500 rows out of 27705\n",
      "processsed: 20000 rows out of 27705\n",
      "processsed: 20500 rows out of 27705\n",
      "processsed: 21000 rows out of 27705\n",
      "processsed: 21500 rows out of 27705\n",
      "processsed: 22000 rows out of 27705\n",
      "processsed: 22500 rows out of 27705\n",
      "processsed: 23000 rows out of 27705\n",
      "processsed: 23500 rows out of 27705\n",
      "processsed: 24000 rows out of 27705\n",
      "processsed: 24500 rows out of 27705\n",
      "processsed: 25000 rows out of 27705\n",
      "processsed: 25500 rows out of 27705\n",
      "processsed: 26000 rows out of 27705\n",
      "processsed: 26500 rows out of 27705\n",
      "processsed: 27000 rows out of 27705\n",
      "processsed: 27500 rows out of 27705\n",
      "[['lie', 'floor', 'feather', 'find', 'hand', 'wanna', 'believe', 'not', 'think', 's', 'god', 'heaven', 'hell', 'lose', 'lookin', 'sign', 'maybe', 'fool', 'swear', 'spine', 'get', 'shiver', 'like', 'kiss', 'time', 'tho', 'tear', 'stream', 'like', 'river', 'know', 'ask', 'sign', 'scare', 'tho', 'body', 'start', 'shakin', 'feel', 'dry', 'eye', 'tho', 'heart', 'break', 'know', 'love', 'sign', 'sign', 'findin', 'street', 'starin', 'reach', 'turn', 'lookin', 'stranger', 'eye', 's', 'god', 'heaven', 'hell', 'tt', 'feel', 'like', 'walk', 'cos', 'touch', 'like', 'swear', 'spine', 'get', 'shiver', 'like', 'kiss', 'time', 'tho', 'tear', 'stream', 'like', 'river', 'know', 'ask', 'sign', 'scare', 'tho', 'body', 'start', 'shakin', 'feel', 'dry', 'eye', 'tho', 'heart', 'break', 'know', 'love', 'sign', 'sign', 'lie', 'floor', 'feather', 'find', 'hand', 'wanna', 'believe', 'not', 'think', 'swear', 'spine', 'get', 'shiver', 'like', 'kiss', 'time', 'tho', 'tear', 'stream', 'like', 'river', 'know', 'ask', 'sign', 'scare', 'tho', 'body', 'start', 'shakin', 'feel', 'dry', 'eye', 'tho', 'heart', 'break', 'know', 'love', 'sign', 'sign'], ['oh', 'lord', 'like', 'know', 'think', 'oh', 'oh', 'lord', 'wanna', 'love', 'life', 'heart', 'wonder', 'right', 'try', 'forget', 'near', 'darle', 'miss', 'darling', 'oh', 'bring', 'darle', 'sweet', 'kiss', 'darle', 'think', 'happy', 'think', 'mistake', 'think', 'darling', 'right', 'wrong', 'near', 'darle', 'miss', 'darling', 'oh', 'bring', 'darle', 'sweet', 'kiss', 'darle', 'oh', 'jah', 'oh', 'jah', 'like', 'near', 'oh', 'jah', 'oh', 'jah', 'miss', 'love']]\n",
      "[[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0    78    18   224   735   249   175   235     9   267  1204   412\n",
      "    541    35   413     9  3797    52   347    78    16   161    10     1\n",
      "     35   394    68    36   177    52     2   136    44     9    52    67\n",
      "   1409   148   787    78    46   418    19    53    16   104   490    52\n",
      "      2  1993    47     5    55     5    55    78    16   161    10     1\n",
      "     35   394    68    36   177    52     2   136    44     9    52    67\n",
      "   1409   148   787    43   207     5   450    16   435     3    16    47\n",
      "     16   100    78   161    20   161    10     1    35   438   107    68\n",
      "     36   177    96   136    44     9    52    67  1409   148   787    78]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0   106   160   281   281   120    12   761   321  2678\n",
      "     10    81   376   706   132   801    15   130   140   123   580   580\n",
      "      2   342   416   139    87   430    14     1    22     5    14   108\n",
      "     22    70   430     1 14839     5    14     1     1 14839     5    14\n",
      "      1     1    14    14    45   187  1320   218    65    86    26    15\n",
      "     78   331   332     3    26  1978   110   130   140   123   580   580\n",
      "      1   136     2     4    13   129   152   342   416   139    87   430\n",
      "   4265    14     1    22     5    14   108    22    70   430     1 14839\n",
      "     14     1     1 14839     5    14     1     1    14     1    22     5\n",
      "     14   108    22    70   430     1    14     1    22     5    14   108\n",
      "     22    70   430     1    14     1    22     5    14   108    22    70\n",
      "    430     1    14     1    22    14    14    14   108 26280 17050 26281]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20118/736918557.py:40: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model_CV = KerasClassifier(build_fn=create_model, epochs=epochs,\n",
      "2023-02-27 16:01:41.040641: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:41.040641: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:41.040651: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:41.040643: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:41.040642: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:41.040657: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:41.040661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:41.040670: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:41.476916: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:41.476919: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:41.476916: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:41.476918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:41.476917: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:41.476916: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:41.476916: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:41.476916: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:41.476940: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 16:01:41.476940: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 16:01:41.476940: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 16:01:41.476940: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 16:01:41.476941: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 16:01:41.476942: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 16:01:41.476944: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 16:01:41.477104: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 16:01:43.608244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.608268: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.608268: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.608281: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.608469: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.608481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 16:01:43.608491: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.608492: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.608501: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.608506: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 16:01:43.608508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 16:01:43.608516: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 16:01:43.608793: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.608899: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.608912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 16:01:43.610301: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.610484: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.610730: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.610750: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 16:01:43.610836: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.610837: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.610880: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 16:01:43.610990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:43.611003: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 16:01:46.519468: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:46.519461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:46.519595: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 16:01:46.519596: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 16:01:46.519592: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:46.519627: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 16:01:46.519633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 16:01:46.519639: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 16:01:46.519657: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:46.519811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 16:01:46.519914: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 16:01:46.519461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:46.520090: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 16:01:46.520119: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 16:01:46.520686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 16:01:46.521333: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:46.521406: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 16:01:46.521440: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 16:01:46.523913: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:46.523986: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 16:01:46.524009: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 16:01:46.532277: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:46.532290: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:46.532308: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:46.532314: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:46.532317: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:46.532323: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:46.532766: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:01:46.546597: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:01:46.546641: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 16:01:46.546683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 16:01:46.547034: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "347/347 [==============================] - 260s 736ms/step - loss: 0.3803 - acc: 0.2774\n",
      "318/347 [==========================>...] - ETA: 23s - loss: 0.1904 - acc: 0.2590Epoch 2/3\n",
      "347/347 [==============================] - 261s 740ms/step - loss: 0.1882 - acc: 0.2680\n",
      "346/347 [============================>.] - ETA: 0s - loss: 0.1902 - acc: 0.2644Epoch 2/3\n",
      "347/347 [==============================] - 263s 746ms/step - loss: 0.2442 - acc: 0.2755\n",
      "325/347 [===========================>..] - ETA: 17s - loss: 0.3189 - acc: 0.2854Epoch 2/3\n",
      "347/347 [==============================] - 264s 747ms/step - loss: 0.1902 - acc: 0.2642\n",
      "  7/347 [..............................] - ETA: 3:29 - loss: 0.3389 - acc: 0.2857Epoch 2/3\n",
      "347/347 [==============================] - 283s 802ms/step - loss: 0.2429 - acc: 0.2742\n",
      " 31/347 [=>............................] - ETA: 3:38 - loss: 0.1798 - acc: 0.2853Epoch 2/3\n",
      "347/347 [==============================] - 284s 804ms/step - loss: 0.3153 - acc: 0.2866\n",
      " 36/347 [==>...........................] - ETA: 3:26 - loss: 0.3649 - acc: 0.2951Epoch 2/3\n",
      "347/347 [==============================] - 284s 807ms/step - loss: 0.1895 - acc: 0.2614\n",
      " 37/347 [==>...........................] - ETA: 3:25 - loss: 0.3669 - acc: 0.2948Epoch 2/3\n",
      "347/347 [==============================] - 300s 853ms/step - loss: 0.1880 - acc: 0.2667\n",
      " 21/347 [>.............................] - ETA: 4:03 - loss: 0.1792 - acc: 0.2798Epoch 2/3\n",
      "347/347 [==============================] - 245s 706ms/step - loss: 0.3676 - acc: 0.2907\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 245s 705ms/step - loss: 0.1797 - acc: 0.2894\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 251s 723ms/step - loss: 0.1789 - acc: 0.2898\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 249s 719ms/step - loss: 0.2180 - acc: 0.2943\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 272s 784ms/step - loss: 0.2232 - acc: 0.2907\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 272s 784ms/step - loss: 0.2645 - acc: 0.2943\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 273s 787ms/step - loss: 0.1797 - acc: 0.2858\n",
      " 64/347 [====>.........................] - ETA: 3:20 - loss: 0.1773 - acc: 0.2993Epoch 3/3\n",
      "347/347 [==============================] - 271s 780ms/step - loss: 0.1786 - acc: 0.2898\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 247s 713ms/step - loss: 0.3665 - acc: 0.2907\n",
      "347/347 [==============================] - 246s 710ms/step - loss: 0.1781 - acc: 0.3005\n",
      "347/347 [==============================] - 248s 715ms/step - loss: 0.1763 - acc: 0.3008\n",
      "347/347 [==============================] - 251s 724ms/step - loss: 0.2175 - acc: 0.2942\n",
      "347/347 [==============================] - 243s 700ms/step - loss: 0.2646 - acc: 0.2943\n",
      "347/347 [==============================] - 244s 705ms/step - loss: 0.2226 - acc: 0.2907\n",
      "347/347 [==============================] - 244s 702ms/step - loss: 0.1773 - acc: 0.2891\n",
      "347/347 [==============================] - 234s 675ms/step - loss: 0.1765 - acc: 0.2977\n",
      "347/347 [==============================] - 49s 74ms/step - loss: 0.3630 - acc: 0.2943\n",
      "347/347 [==============================] - 48s 72ms/step - loss: 0.1783 - acc: 0.3108\n",
      "347/347 [==============================] - 45s 65ms/step - loss: 0.1835 - acc: 0.3084\n",
      "347/347 [==============================] - 42s 55ms/step - loss: 0.2224 - acc: 0.2907\n",
      "347/347 [==============================] - 28s 56ms/step - loss: 0.2175 - acc: 0.2943\n",
      "347/347 [==============================] - 29s 59ms/step - loss: 0.2676 - acc: 0.2907\n",
      "347/347 [==============================] - 28s 58ms/step - loss: 0.1738 - acc: 0.3024\n",
      "347/347 [==============================] - 26s 54ms/step - loss: 0.1758 - acc: 0.2943\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "  1/347 [..............................] - ETA: 27:04 - loss: 1.5048 - acc: 0.0000e+00Epoch 1/3\n",
      "347/347 [==============================] - 464s 1s/step - loss: 0.3632 - acc: 0.2827\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 498s 1s/step - loss: 0.1894 - acc: 0.2639\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 500s 1s/step - loss: 0.8239 - acc: 0.1225\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 505s 1s/step - loss: 0.1887 - acc: 0.2676\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 578s 2s/step - loss: 0.1895 - acc: 0.2591\n",
      " 56/347 [===>..........................] - ETA: 6:59 - loss: 0.1806 - acc: 0.2885Epoch 2/3\n",
      "347/347 [==============================] - 583s 2s/step - loss: 0.2784 - acc: 0.2811\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 586s 2s/step - loss: 1.2505 - acc: 0.0993\n",
      " 56/347 [===>..........................] - ETA: 7:02 - loss: 0.1805 - acc: 0.2757Epoch 2/3\n",
      "347/347 [==============================] - 589s 2s/step - loss: 0.1877 - acc: 0.2621\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 485s 1s/step - loss: 0.2805 - acc: 0.2907\n",
      "216/347 [=================>............] - ETA: 3:37 - loss: 0.7738 - acc: 0.1777Epoch 3/3\n",
      "347/347 [==============================] - 487s 1s/step - loss: 0.7689 - acc: 0.1835\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 491s 1s/step - loss: 0.1797 - acc: 0.2844\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 488s 1s/step - loss: 0.1783 - acc: 0.2897\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 569s 2s/step - loss: 0.1798 - acc: 0.2849\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 572s 2s/step - loss: 0.2206 - acc: 0.2941\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 573s 2s/step - loss: 0.7684 - acc: 0.1842\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 575s 2s/step - loss: 0.1784 - acc: 0.2898\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 479s 1s/step - loss: 0.2715 - acc: 0.2907\n",
      "347/347 [==============================] - 478s 1s/step - loss: 0.6839 - acc: 0.1836\n",
      "347/347 [==============================] - 478s 1s/step - loss: 0.1789 - acc: 0.2867\n",
      "347/347 [==============================] - 482s 1s/step - loss: 0.1774 - acc: 0.2948\n",
      "347/347 [==============================] - 103s 280ms/step - loss: 0.2659 - acc: 0.2943\n",
      "240/347 [===================>..........] - ETA: 2:46 - loss: 0.7640 - acc: 0.1824Epoch 1/3\n",
      "347/347 [==============================] - 95s 265ms/step - loss: 0.6727 - acc: 0.1842\n",
      "347/347 [==============================] - 96s 265ms/step - loss: 0.1756 - acc: 0.2943\n",
      "335/347 [===========================>..] - ETA: 2s - loss: 0.1772 - acc: 0.3016Epoch 1/3\n",
      "341/347 [============================>.] - ETA: 1s - loss: 0.1773 - acc: 0.3014Epoch 1/3\n",
      "347/347 [==============================] - 89s 244ms/step - loss: 0.1773 - acc: 0.3020\n",
      "347/347 [==============================] - 500s 1s/step - loss: 0.1786 - acc: 0.2894\n",
      "347/347 [==============================] - 498s 1s/step - loss: 0.7358 - acc: 0.1816\n",
      "347/347 [==============================] - 502s 1s/step - loss: 0.2177 - acc: 0.2943\n",
      "347/347 [==============================] - 497s 1s/step - loss: 0.1773 - acc: 0.2919\n",
      "262/347 [=====================>........] - ETA: 36s - loss: 0.2682 - acc: 0.2582Epoch 1/3\n",
      "347/347 [==============================] - 179s 408ms/step - loss: 0.2578 - acc: 0.2691\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 81s 221ms/step - loss: 0.1755 - acc: 0.2943\n",
      " 59/347 [====>.........................] - ETA: 2:39 - loss: 0.2255 - acc: 0.2918Epoch 1/3\n",
      "347/347 [==============================] - 198s 474ms/step - loss: 0.1923 - acc: 0.2624\n",
      "195/347 [===============>..............] - ETA: 1:26 - loss: 0.1948 - acc: 0.2412Epoch 2/3\n",
      "347/347 [==============================] - 200s 478ms/step - loss: 0.2838 - acc: 0.2693\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 119s 333ms/step - loss: 0.2224 - acc: 0.2907\n",
      "347/347 [==============================] - 119s 331ms/step - loss: 0.6718 - acc: 0.1835\n",
      "347/347 [==============================] - 121s 334ms/step - loss: 0.1774 - acc: 0.2907\n",
      " 87/347 [======>.......................] - ETA: 2:12 - loss: 0.1821 - acc: 0.2859Epoch 1/3\n",
      "121/347 [=========>....................] - ETA: 2:14 - loss: 0.4621 - acc: 0.2162Epoch 1/3\n",
      " 98/347 [=======>......................] - ETA: 2:06 - loss: 0.2222 - acc: 0.2899Epoch 1/3\n",
      "347/347 [==============================] - 211s 538ms/step - loss: 0.1884 - acc: 0.2657\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 186s 535ms/step - loss: 0.2229 - acc: 0.2907\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 275s 656ms/step - loss: 0.3416 - acc: 0.2492\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 205s 590ms/step - loss: 0.1798 - acc: 0.2841\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 210s 607ms/step - loss: 0.2238 - acc: 0.2943\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 239s 689ms/step - loss: 0.2223 - acc: 0.2924\n",
      "347/347 [==============================] - 243s 701ms/step - loss: 0.1785 - acc: 0.2934\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 300s 752ms/step - loss: 0.2382 - acc: 0.2788\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 303s 759ms/step - loss: 0.1907 - acc: 0.2555\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 305s 754ms/step - loss: 0.1897 - acc: 0.2666\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 48s 122ms/step - loss: 0.2169 - acc: 0.2943\n",
      "347/347 [==============================] - 229s 659ms/step - loss: 0.1788 - acc: 0.2917\n",
      "347/347 [==============================] - 228s 658ms/step - loss: 0.2179 - acc: 0.2942\n",
      "347/347 [==============================] - 246s 709ms/step - loss: 0.2618 - acc: 0.2907\n",
      "138/347 [==========>...................] - ETA: 2:19 - loss: 0.1793 - acc: 0.2772Epoch 3/3\n",
      "182/347 [==============>...............] - ETA: 1:49 - loss: 0.1805 - acc: 0.2804Epoch 1/3\n",
      "347/347 [==============================] - 38s 97ms/step - loss: 0.2226 - acc: 0.2907\n",
      "269/347 [======================>.......] - ETA: 8s - loss: 0.1770 - acc: 0.2921Epoch 1/3\n",
      "347/347 [==============================] - 40s 103ms/step - loss: 0.1770 - acc: 0.2943\n",
      "241/347 [===================>..........] - ETA: 1:07 - loss: 0.1806 - acc: 0.2811Epoch 1/3\n",
      "347/347 [==============================] - 196s 563ms/step - loss: 0.1759 - acc: 0.3073\n",
      "347/347 [==============================] - 203s 586ms/step - loss: 0.2184 - acc: 0.2942\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 208s 599ms/step - loss: 0.1799 - acc: 0.2847\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 203s 584ms/step - loss: 0.1783 - acc: 0.2915\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 43s 111ms/step - loss: 0.1781 - acc: 0.3049\n",
      "125/347 [=========>....................] - ETA: 2:15 - loss: 0.2168 - acc: 0.3000Epoch 1/3\n",
      "347/347 [==============================] - 195s 562ms/step - loss: 0.2615 - acc: 0.2908\n",
      "347/347 [==============================] - 48s 125ms/step - loss: 0.2509 - acc: 0.2943\n",
      " 66/347 [====>.........................] - ETA: 5:52 - loss: 0.2128 - acc: 0.2188Epoch 1/3\n",
      "347/347 [==============================] - 209s 602ms/step - loss: 0.2175 - acc: 0.2943\n",
      "347/347 [==============================] - 209s 603ms/step - loss: 0.1762 - acc: 0.2985\n",
      "347/347 [==============================] - 214s 616ms/step - loss: 0.1782 - acc: 0.2923\n",
      "347/347 [==============================] - 38s 98ms/step - loss: 0.2231 - acc: 0.2907\n",
      "210/347 [=================>............] - ETA: 13s - loss: 0.1744 - acc: 0.3031Epoch 1/3\n",
      "347/347 [==============================] - 39s 104ms/step - loss: 0.1753 - acc: 0.3030\n",
      "253/347 [====================>.........] - ETA: 1:48 - loss: 0.3539 - acc: 0.2646Epoch 1/3\n",
      "347/347 [==============================] - 45s 119ms/step - loss: 0.1795 - acc: 0.2948\n",
      "347/347 [==============================] - 434s 1s/step - loss: 0.5260 - acc: 0.2787\n",
      "Epoch 2/3\n",
      " 66/347 [====>.........................] - ETA: 6:13 - loss: 0.4586 - acc: 0.2557Epoch 1/3\n",
      "347/347 [==============================] - 433s 1s/step - loss: 0.3334 - acc: 0.2711\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 430s 1s/step - loss: 0.1887 - acc: 0.2638\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 451s 1s/step - loss: 0.1878 - acc: 0.2688\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 532s 1s/step - loss: 0.4631 - acc: 0.2756\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 528s 1s/step - loss: 0.4173 - acc: 0.2849\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 446s 1s/step - loss: 0.3251 - acc: 0.2907\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 445s 1s/step - loss: 0.2775 - acc: 0.2939\n",
      "337/347 [============================>.] - ETA: 12s - loss: 0.1800 - acc: 0.2825Epoch 3/3\n",
      "347/347 [==============================] - 556s 1s/step - loss: 0.1894 - acc: 0.2569\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 449s 1s/step - loss: 0.1799 - acc: 0.2835\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 577s 2s/step - loss: 0.1872 - acc: 0.2700\n",
      "Epoch 2/3\n",
      "347/347 [==============================] - 447s 1s/step - loss: 0.1786 - acc: 0.2879\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 455s 1s/step - loss: 0.3249 - acc: 0.2907\n",
      "347/347 [==============================] - 526s 2s/step - loss: 0.3609 - acc: 0.2907\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 452s 1s/step - loss: 0.2764 - acc: 0.2943\n",
      "347/347 [==============================] - 451s 1s/step - loss: 0.1781 - acc: 0.2970\n",
      "347/347 [==============================] - 513s 1s/step - loss: 0.3558 - acc: 0.2911\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 510s 1s/step - loss: 0.1797 - acc: 0.2848\n",
      "104/347 [=======>......................] - ETA: 59s - loss: 0.3202 - acc: 0.2915Epoch 3/3\n",
      "347/347 [==============================] - 96s 259ms/step - loss: 0.3214 - acc: 0.2943\n",
      "347/347 [==============================] - 427s 1s/step - loss: 0.1770 - acc: 0.2959\n",
      "347/347 [==============================] - 95s 256ms/step - loss: 0.2836 - acc: 0.2907\n",
      "347/347 [==============================] - 95s 256ms/step - loss: 0.1753 - acc: 0.2972\n",
      "347/347 [==============================] - 492s 1s/step - loss: 0.1787 - acc: 0.2886\n",
      "Epoch 3/3\n",
      "347/347 [==============================] - 81s 219ms/step - loss: 0.1763 - acc: 0.2925\n",
      "347/347 [==============================] - 341s 983ms/step - loss: 0.3102 - acc: 0.2904\n",
      "347/347 [==============================] - 323s 929ms/step - loss: 0.3442 - acc: 0.2943\n",
      "347/347 [==============================] - 307s 884ms/step - loss: 0.1784 - acc: 0.2902\n",
      "347/347 [==============================] - 48s 132ms/step - loss: 0.3469 - acc: 0.2907\n",
      "347/347 [==============================] - 48s 133ms/step - loss: 0.2173 - acc: 0.2943\n",
      "347/347 [==============================] - 246s 707ms/step - loss: 0.1777 - acc: 0.2927\n",
      "347/347 [==============================] - 43s 119ms/step - loss: 0.1755 - acc: 0.3045\n",
      "347/347 [==============================] - 24s 69ms/step - loss: 0.1769 - acc: 0.2907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 17:24:06.764515: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "693/693 [==============================] - 67s 93ms/step - loss: 0.1843 - acc: 0.2782\n",
      "Epoch 2/3\n",
      "693/693 [==============================] - 61s 88ms/step - loss: 0.1757 - acc: 0.3183\n",
      "Epoch 3/3\n",
      "693/693 [==============================] - 61s 88ms/step - loss: 0.1715 - acc: 0.3392\n",
      "Best Accuracy for dataset ./data/song-data-labels-cleaned.csv is: 0.30960115790367126 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2925, std=0.00176 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.3096, std=0.001173 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2925, std=0.00176 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2983, std=0.004061 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2392, std=0.05504 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2981, std=0.00388 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2371, std=0.0536 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2925, std=0.00176 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2925, std=0.00176 using {'adapt_embedding': False, 'filters': 50, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2996, std=0.005324 using {'adapt_embedding': False, 'filters': 50, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2925, std=0.00176 using {'adapt_embedding': False, 'filters': 50, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2989, std=0.004106 using {'adapt_embedding': False, 'filters': 50, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2925, std=0.00176 using {'adapt_embedding': False, 'filters': 100, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2949, std=0.002346 using {'adapt_embedding': False, 'filters': 100, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2925, std=0.00176 using {'adapt_embedding': False, 'filters': 100, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      " mean=0.2976, std=0.006903 using {'adapt_embedding': False, 'filters': 100, 'kernel': 5, 'mood_count': 17, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f271c671e10>}\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "test_dataset(\"./data/song-data-labels-cleaned.csv\", 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba28144",
   "metadata": {},
   "source": [
    "## Test the dataset with only 4 moods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1acb4a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing now dataset ./data/song-data-labels-cleaned-quadrant.csv with 4 moods\n",
      "['happy' 'sad' 'calm' 'anger']\n",
      "processsed: 500 rows out of 8176\n",
      "processsed: 1000 rows out of 8176\n",
      "processsed: 1500 rows out of 8176\n",
      "processsed: 2000 rows out of 8176\n",
      "processsed: 2500 rows out of 8176\n",
      "processsed: 3000 rows out of 8176\n",
      "processsed: 3500 rows out of 8176\n",
      "processsed: 4000 rows out of 8176\n",
      "processsed: 4500 rows out of 8176\n",
      "processsed: 5000 rows out of 8176\n",
      "processsed: 5500 rows out of 8176\n",
      "processsed: 6000 rows out of 8176\n",
      "processsed: 6500 rows out of 8176\n",
      "processsed: 7000 rows out of 8176\n",
      "processsed: 7500 rows out of 8176\n",
      "processsed: 8000 rows out of 8176\n",
      "[['oh', 'lord', 'like', 'know', 'think', 'oh', 'oh', 'lord', 'wanna', 'love', 'life', 'heart', 'wonder', 'right', 'try', 'forget', 'near', 'darle', 'miss', 'darling', 'oh', 'bring', 'darle', 'sweet', 'kiss', 'darle', 'think', 'happy', 'think', 'mistake', 'think', 'darling', 'right', 'wrong', 'near', 'darle', 'miss', 'darling', 'oh', 'bring', 'darle', 'sweet', 'kiss', 'darle', 'oh', 'jah', 'oh', 'jah', 'like', 'near', 'oh', 'jah', 'oh', 'jah', 'miss', 'love'], ['bring', 'beat', 'honey', 'honey', 'star', 'way', 'glow', 'window', 'pane', 'feel', 'sun', 'near', 'everytime', 'touch', 'melt', 'away', 'everybody', 'ask', 'smile', 'ear', 'ear', 'know', 'perfect', 'worth', 'fight', 'tear', 'finally', 'baby', 'love', 'need', 'come', 'baby', 'give', 'need', 'stop', 'finally', 'love', 'huum', 'come', 'baby', 'love', 'love', 'huum', 'come', 'baby', 'love', 'love', 'baby', 'baby', 'hear', 'wind', 'whip', 'pass', 'face', 'dance', 'night', 'away', 'boy', 'lip', 'taste', 'like', 'night', 'champagne', 'kiss', 'everybody', 'ask', 'smile', 'ear', 'ear', 'love', 'hurt', 'know', 'go', 'to', 'real', 'work', 'perfect', 'worth', 'fight', 'tear', 'finally', '1st', 'baby', 'love', 'need', 'come', 'baby', 'give', 'need', 'stop', 'finally', 'love', 'huum', 'baby', 'love', 'love', 'huum', 'come', 'baby', 'love', 'love', 'baby', 'love', 'need', 'come', 'baby', 'give', 'need', 'stop', 'finally', 'love', 'baby', 'love', 'need', 'come', 'baby', 'give', 'need', 'stop', 'finally', 'love', 'baby', 'love', 'need', 'come', 'baby', 'give', 'need', 'stop', 'finally', 'love', 'baby', 'love', 'need', 'baby', 'baby', 'baby', 'give', 'cridto', 'leandro', 'cesar12']]\n",
      "[[  384 14646   993   355   245   787    92    17    20  3487  1551   250\n",
      "    914    56    47   393   192    10     3   140    56     3  1441   293\n",
      "      3  1441   293   455     9     3  1441   293   494     7     7     7\n",
      "      7     7     7     7     7     7     7     7   494     7     7     7\n",
      "      7     7     7     7     7     7     7     7    56     3  1441   293\n",
      "      3  1441   293   455     9     3  1441   293   494     7     7     7\n",
      "      7     7     7     7     7     7     7     7   494     7     7     7\n",
      "      7     7     7     7     7     7     7     7   469    28    34   226\n",
      "     35     2  3488   723    29   111    68  1350   915  2474   237   181\n",
      "      9     3   472     5   489   299   489   299   489   299   489   299\n",
      "     45   494     7     7     7     7     7     7     7     7     7     7\n",
      "      7   494     7     7     7     7     7     7     7     7     7     7\n",
      "      7   494     7     7     7    56     3  1441   293     3  1441   293\n",
      "    455     9     3  1441   293   494     7     7     7    56     3  1441\n",
      "    293     3  1441   293   455     9     3  1441   293   494     7     7]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     6    45    39    11    76     2\n",
      "   1255   112    30     2    74     8    12   265    11     2     3   157\n",
      "     11    15   448     8    41   130   169    34    41  1475    35     6\n",
      "     45    39    11    76     2  1255   112    30     2    74     8    12\n",
      "    265    11     2     3   157    11    12     6     9    24     2    12\n",
      "     11    24  2805     2   106    37  2475     2    11     2    60   889\n",
      "     12    11    65     6    11    47   134    87   378   265   201    22\n",
      "    110    11     2    49    99   267  2883    24     2    10    12    24\n",
      "     24    40    11    98     2     6    45    39    11    76     2  1255\n",
      "    112    30     2    74     8    12   265    11     2     3   157    11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20118/736918557.py:40: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model_CV = KerasClassifier(build_fn=create_model, epochs=epochs,\n",
      "2023-02-27 22:40:01.095204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:01.095205: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:01.095614: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:01.095625: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:01.095834: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:01.096271: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:01.096300: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:01.097225: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:02.445984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:02.445985: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:02.445996: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:02.446009: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:02.446011: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:02.446016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:02.446029: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 22:40:02.446016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:02.446035: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 22:40:02.446046: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 22:40:02.446045: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 22:40:02.446049: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 22:40:02.446047: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 22:40:02.446243: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:02.446271: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 22:40:02.446316: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 22:40:06.984340: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.984433: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.984473: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.984471: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.984473: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.984476: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.984493: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.984554: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.985731: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.985731: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.985731: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.985730: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.985730: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.985749: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.985770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:40:06.985770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:40:06.985770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:40:06.985770: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:40:06.985782: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:40:06.986005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:40:06.986246: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.986245: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:06.986282: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 22:40:06.986342: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 22:40:12.861598: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:12.861598: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:12.861598: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:12.861598: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:12.861598: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:12.862359: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:12.862548: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 22:40:12.862598: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 22:40:12.862634: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 22:40:12.862635: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 22:40:12.862653: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 22:40:12.862667: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 22:40:12.862700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 22:40:12.862699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 22:40:12.862755: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 22:40:12.862792: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 22:40:12.862812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 22:40:12.862849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 22:40:12.864000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:12.864000: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:12.864037: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:12.864110: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:12.864308: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:12.866247: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:12.867728: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:12.868094: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 22:40:12.868380: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 22:40:12.869056: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 22:40:12.869870: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 22:40:12.870079: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 22:40:12.870331: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 22:40:12.871345: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "103/103 [==============================] - 73s 648ms/step - loss: 0.5699 - acc: 0.2700\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 79s 703ms/step - loss: 0.5699 - acc: 0.2612\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 79s 676ms/step - loss: 1.5249 - acc: 0.2462\n",
      "102/103 [============================>.] - ETA: 0s - loss: 0.9404 - acc: 0.2488Epoch 2/3\n",
      "103/103 [==============================] - 79s 679ms/step - loss: 0.5709 - acc: 0.2367\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 80s 713ms/step - loss: 0.9397 - acc: 0.2489\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 82s 731ms/step - loss: 0.6877 - acc: 0.2578\n",
      "  3/103 [..............................] - ETA: 1:05 - loss: 1.2869 - acc: 0.2604Epoch 2/3\n",
      "103/103 [==============================] - 83s 705ms/step - loss: 0.8284 - acc: 0.2361\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 85s 744ms/step - loss: 0.5701 - acc: 0.2532\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 69s 668ms/step - loss: 0.5658 - acc: 0.2618\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 69s 669ms/step - loss: 0.5647 - acc: 0.2768\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 70s 680ms/step - loss: 1.3911 - acc: 0.2557\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 69s 668ms/step - loss: 0.5675 - acc: 0.2520\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 76s 737ms/step - loss: 0.5636 - acc: 0.2691\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 77s 751ms/step - loss: 0.5680 - acc: 0.2639\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 76s 742ms/step - loss: 0.5669 - acc: 0.2694\n",
      " 13/103 [==>...........................] - ETA: 57s - loss: 1.3441 - acc: 0.2692Epoch 3/3\n",
      "103/103 [==============================] - 76s 735ms/step - loss: 0.5635 - acc: 0.2752\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 69s 672ms/step - loss: 0.5625 - acc: 0.2905\n",
      "103/103 [==============================] - 67s 653ms/step - loss: 1.3877 - acc: 0.2694\n",
      "103/103 [==============================] - 69s 673ms/step - loss: 0.5616 - acc: 0.2914\n",
      "103/103 [==============================] - 66s 643ms/step - loss: 0.5652 - acc: 0.2667\n",
      "103/103 [==============================] - 70s 678ms/step - loss: 0.5559 - acc: 0.3012\n",
      "103/103 [==============================] - 67s 649ms/step - loss: 0.5650 - acc: 0.2636\n",
      "103/103 [==============================] - 68s 659ms/step - loss: 0.5644 - acc: 0.2734\n",
      "103/103 [==============================] - 66s 634ms/step - loss: 0.5566 - acc: 0.2991\n",
      "103/103 [==============================] - 9s 60ms/step - loss: 0.5710 - acc: 0.2654\n",
      " 32/103 [========>.....................] - ETA: 1s - loss: 0.5536 - acc: 0.3613Epoch 1/3\n",
      "103/103 [==============================] - 3s 25ms/step - loss: 0.5546 - acc: 0.3361\n",
      "Epoch 1/3\n",
      "103/103 [==============================] - 42s 359ms/step - loss: 3.5358 - acc: 0.2547\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 15s 127ms/step - loss: 0.5634 - acc: 0.3076\n",
      "103/103 [==============================] - 17s 148ms/step - loss: 0.5739 - acc: 0.3168\n",
      "103/103 [==============================] - 17s 149ms/step - loss: 0.5672 - acc: 0.2930\n",
      "103/103 [==============================] - 18s 150ms/step - loss: 0.5592 - acc: 0.3358\n",
      "103/103 [==============================] - 57s 498ms/step - loss: 0.8975 - acc: 0.2529\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 16s 116ms/step - loss: 1.3882 - acc: 0.2550\n",
      "103/103 [==============================] - 17s 123ms/step - loss: 0.5650 - acc: 0.3352\n",
      "  6/103 [>.............................] - ETA: 42s - loss: 0.5668 - acc: 0.2917Epoch 1/3\n",
      " 11/103 [==>...........................] - ETA: 43s - loss: 0.5698 - acc: 0.2585Epoch 1/3\n",
      "Epoch 1/3\n",
      " 27/103 [======>.......................] - ETA: 1:05 - loss: 1.7186 - acc: 0.2396Epoch 1/3\n",
      " 12/103 [==>...........................] - ETA: 43s - loss: 0.5695 - acc: 0.2552Epoch 1/3\n",
      " 40/103 [==========>...................] - ETA: 47s - loss: 1.3501 - acc: 0.2383Epoch 1/3\n",
      "103/103 [==============================] - 107s 1s/step - loss: 0.8743 - acc: 0.2468\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 113s 1s/step - loss: 0.5682 - acc: 0.2535\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 163s 1s/step - loss: 0.5736 - acc: 0.2468\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 175s 2s/step - loss: 0.5710 - acc: 0.2477\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 201s 2s/step - loss: 9.4518 - acc: 0.2459\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 204s 2s/step - loss: 1.7835 - acc: 0.2471\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 210s 2s/step - loss: 0.5719 - acc: 0.2538\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 221s 2s/step - loss: 0.5723 - acc: 0.2572\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 159s 2s/step - loss: 0.5648 - acc: 0.2630\n",
      "103/103 [==============================] - 158s 2s/step - loss: 0.5644 - acc: 0.2801\n",
      "103/103 [==============================] - 42s 368ms/step - loss: 0.5592 - acc: 0.3352\n",
      " 91/103 [=========================>....] - ETA: 17s - loss: 0.5643 - acc: 0.2610Epoch 1/3\n",
      "103/103 [==============================] - 150s 1s/step - loss: 0.5649 - acc: 0.2777\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 148s 1s/step - loss: 0.5649 - acc: 0.2618\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 46s 397ms/step - loss: 0.5751 - acc: 0.2792\n",
      "103/103 [==============================] - 175s 2s/step - loss: 9.5476 - acc: 0.2581\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 172s 2s/step - loss: 1.0450 - acc: 0.2474\n",
      "Epoch 3/3\n",
      " 90/103 [=========================>....] - ETA: 21s - loss: 0.5635 - acc: 0.2816Epoch 1/3\n",
      "103/103 [==============================] - 171s 2s/step - loss: 0.5656 - acc: 0.2599\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 171s 2s/step - loss: 0.5639 - acc: 0.2804\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 109s 619ms/step - loss: 0.7538 - acc: 0.2563\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 148s 1s/step - loss: 0.5556 - acc: 0.3199\n",
      "103/103 [==============================] - 151s 1s/step - loss: 0.5568 - acc: 0.2994\n",
      "103/103 [==============================] - 61s 596ms/step - loss: 0.5676 - acc: 0.2716\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 113s 569ms/step - loss: 1.2353 - acc: 0.2615\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 54s 525ms/step - loss: 0.5643 - acc: 0.2835\n",
      "103/103 [==============================] - 169s 2s/step - loss: 0.5655 - acc: 0.2777\n",
      "103/103 [==============================] - 170s 2s/step - loss: 9.5476 - acc: 0.2508\n",
      "103/103 [==============================] - 56s 544ms/step - loss: 0.5664 - acc: 0.2713\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 167s 2s/step - loss: 0.5625 - acc: 0.2722\n",
      "103/103 [==============================] - 39s 339ms/step - loss: 0.5444 - acc: 0.3746\n",
      "103/103 [==============================] - 37s 302ms/step - loss: 0.5455 - acc: 0.3199\n",
      "103/103 [==============================] - 158s 2s/step - loss: 0.5580 - acc: 0.2798\n",
      " 48/103 [============>.................] - ETA: 2s - loss: 0.5753 - acc: 0.2630Epoch 1/3\n",
      "103/103 [==============================] - 6s 44ms/step - loss: 0.5749 - acc: 0.2557\n",
      " 73/103 [====================>.........] - ETA: 6s - loss: 0.5643 - acc: 0.2637Epoch 1/3\n",
      "103/103 [==============================] - 19s 183ms/step - loss: 0.5641 - acc: 0.2657\n",
      "Epoch 1/3\n",
      "103/103 [==============================] - 5s 45ms/step - loss: 0.5740 - acc: 0.2792\n",
      " 32/103 [========>.....................] - ETA: 12s - loss: 0.5799 - acc: 0.2441Epoch 1/3\n",
      "103/103 [==============================] - 38s 299ms/step - loss: 0.5705 - acc: 0.2557\n",
      " 44/103 [===========>..................] - ETA: 21s - loss: 0.5710 - acc: 0.2592Epoch 2/3\n",
      "103/103 [==============================] - 49s 398ms/step - loss: 0.5723 - acc: 0.2477\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 45s 415ms/step - loss: 9.5359 - acc: 0.2550\n",
      "103/103 [==============================] - 46s 416ms/step - loss: 0.5717 - acc: 0.2502\n",
      " 99/103 [===========================>..] - ETA: 1s - loss: 0.5557 - acc: 0.2857Epoch 1/3\n",
      "103/103 [==============================] - 46s 420ms/step - loss: 0.5552 - acc: 0.2865\n",
      "103/103 [==============================] - 65s 535ms/step - loss: 0.6422 - acc: 0.2578\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 43s 372ms/step - loss: 0.5595 - acc: 0.2936\n",
      "103/103 [==============================] - 50s 489ms/step - loss: 0.5619 - acc: 0.2817\n",
      "Epoch 3/3\n",
      " 43/103 [===========>..................] - ETA: 26s - loss: 0.5664 - acc: 0.2565Epoch 1/3\n",
      "103/103 [==============================] - 81s 522ms/step - loss: 0.7512 - acc: 0.2450\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 46s 443ms/step - loss: 0.5661 - acc: 0.2471\n",
      "Epoch 3/3\n",
      " 53/103 [==============>...............] - ETA: 18s - loss: 0.5514 - acc: 0.3343Epoch 1/3\n",
      " 42/103 [===========>..................] - ETA: 26s - loss: 0.5686 - acc: 0.2403Epoch 1/3\n",
      "103/103 [==============================] - 45s 435ms/step - loss: 0.5670 - acc: 0.2575\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 42s 412ms/step - loss: 0.5529 - acc: 0.3284\n",
      "103/103 [==============================] - 50s 487ms/step - loss: 0.5680 - acc: 0.2502\n",
      "100/103 [============================>.] - ETA: 1s - loss: 0.5653 - acc: 0.2509Epoch 3/3\n",
      "103/103 [==============================] - 47s 454ms/step - loss: 0.5652 - acc: 0.2535\n",
      "103/103 [==============================] - 17s 124ms/step - loss: 0.5505 - acc: 0.3138\n",
      "103/103 [==============================] - 81s 503ms/step - loss: 0.5711 - acc: 0.2645\n",
      "  2/103 [..............................] - ETA: 1:44 - loss: 5.0163 - acc: 0.2812   Epoch 2/3\n",
      " 67/103 [==================>...........] - ETA: 19s - loss: 0.5624 - acc: 0.2929Epoch 1/3\n",
      "103/103 [==============================] - 17s 132ms/step - loss: 0.5673 - acc: 0.2713\n",
      " 12/103 [==>...........................] - ETA: 1:58 - loss: 3.4513 - acc: 0.2292Epoch 1/3\n",
      "103/103 [==============================] - 57s 557ms/step - loss: 0.5630 - acc: 0.2963\n",
      "103/103 [==============================] - 89s 540ms/step - loss: 0.5693 - acc: 0.2599\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 53s 510ms/step - loss: 0.5652 - acc: 0.2697\n",
      "103/103 [==============================] - 53s 517ms/step - loss: 0.5675 - acc: 0.2606\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 54s 520ms/step - loss: 0.5671 - acc: 0.2535\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 21s 165ms/step - loss: 0.5779 - acc: 0.2725\n",
      "  8/103 [=>............................] - ETA: 17s - loss: 0.5727 - acc: 0.2344Epoch 1/3\n",
      "103/103 [==============================] - 60s 585ms/step - loss: 0.5608 - acc: 0.2853\n",
      "103/103 [==============================] - 21s 156ms/step - loss: 0.5730 - acc: 0.2456\n",
      "103/103 [==============================] - 162s 1s/step - loss: 7.6350 - acc: 0.2498\n",
      "Epoch 2/3\n",
      " 67/103 [==================>...........] - ETA: 20s - loss: 0.5616 - acc: 0.2761Epoch 1/3\n",
      "103/103 [==============================] - 161s 1s/step - loss: 3.0908 - acc: 0.2453\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 55s 531ms/step - loss: 0.5581 - acc: 0.2936\n",
      "103/103 [==============================] - 159s 1s/step - loss: 0.5732 - acc: 0.2477\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 20s 155ms/step - loss: 0.5667 - acc: 0.2667\n",
      " 49/103 [=============>................] - ETA: 1:00 - loss: 7.7640 - acc: 0.2321Epoch 1/3\n",
      "103/103 [==============================] - 159s 1s/step - loss: 0.5706 - acc: 0.2532\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 22s 166ms/step - loss: 0.5538 - acc: 0.3193\n",
      " 22/103 [=====>........................] - ETA: 1:51 - loss: 0.5679 - acc: 0.2173Epoch 1/3\n",
      "103/103 [==============================] - 125s 1s/step - loss: 7.6841 - acc: 0.2352\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 125s 1s/step - loss: 3.0310 - acc: 0.2492\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 207s 2s/step - loss: 2.2505 - acc: 0.2602\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 145s 1s/step - loss: 0.5668 - acc: 0.2517\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 153s 1s/step - loss: 0.5655 - acc: 0.2459\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 210s 2s/step - loss: 7.5671 - acc: 0.2547\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 232s 2s/step - loss: 0.5723 - acc: 0.2563\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 164s 2s/step - loss: 7.6841 - acc: 0.2413\n",
      "103/103 [==============================] - 167s 2s/step - loss: 2.3932 - acc: 0.2422\n",
      "103/103 [==============================] - 242s 2s/step - loss: 0.5698 - acc: 0.2664\n",
      "Epoch 2/3\n",
      "103/103 [==============================] - 44s 381ms/step - loss: 7.6091 - acc: 0.2550\n",
      "103/103 [==============================] - 158s 2s/step - loss: 0.5649 - acc: 0.2450\n",
      "103/103 [==============================] - 154s 1s/step - loss: 0.5625 - acc: 0.2869\n",
      "103/103 [==============================] - 180s 2s/step - loss: 1.4038 - acc: 0.2584\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 41s 351ms/step - loss: 0.5625 - acc: 0.2584\n",
      "103/103 [==============================] - 170s 2s/step - loss: 7.6395 - acc: 0.2425\n",
      " 63/103 [=================>............] - ETA: 59s - loss: 0.5667 - acc: 0.2495 Epoch 3/3\n",
      "103/103 [==============================] - 32s 288ms/step - loss: 0.5627 - acc: 0.2685\n",
      "103/103 [==============================] - 33s 282ms/step - loss: 0.5626 - acc: 0.2508\n",
      "103/103 [==============================] - 138s 1s/step - loss: 0.5664 - acc: 0.2578\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 120s 1s/step - loss: 0.5658 - acc: 0.2557\n",
      "Epoch 3/3\n",
      "103/103 [==============================] - 106s 1s/step - loss: 1.3997 - acc: 0.3021\n",
      "103/103 [==============================] - 99s 962ms/step - loss: 7.6395 - acc: 0.2520\n",
      "103/103 [==============================] - 73s 711ms/step - loss: 0.5638 - acc: 0.2697\n",
      "103/103 [==============================] - 61s 589ms/step - loss: 0.5620 - acc: 0.2584\n",
      "103/103 [==============================] - 12s 109ms/step - loss: 0.5590 - acc: 0.3135\n",
      "103/103 [==============================] - 8s 66ms/step - loss: 0.5616 - acc: 0.2572\n",
      "103/103 [==============================] - 6s 58ms/step - loss: 1.4016 - acc: 0.3171\n",
      "103/103 [==============================] - 7s 64ms/step - loss: 7.6536 - acc: 0.2450\n",
      "Epoch 1/3\n",
      "205/205 [==============================] - 45s 196ms/step - loss: 0.5684 - acc: 0.2552\n",
      "Epoch 2/3\n",
      "205/205 [==============================] - 41s 201ms/step - loss: 0.5615 - acc: 0.2742\n",
      "Epoch 3/3\n",
      "205/205 [==============================] - 44s 215ms/step - loss: 0.5309 - acc: 0.3853\n",
      "Best Accuracy for dataset ./data/song-data-labels-cleaned-quadrant.csv is: 0.3472477048635483 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.2602, std=0.005199 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.3214, std=0.01376 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.3144, std=0.02141 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.3265, std=0.009633 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.3072, std=0.02798 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.3472, std=0.02737 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.2526, std=0.002446 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.2901, std=0.003517 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.2674, std=0.01177 using {'adapt_embedding': False, 'filters': 50, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.2925, std=0.02125 using {'adapt_embedding': False, 'filters': 50, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.259, std=0.01346 using {'adapt_embedding': False, 'filters': 50, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.293, std=0.0263 using {'adapt_embedding': False, 'filters': 50, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.2567, std=0.001682 using {'adapt_embedding': False, 'filters': 100, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.2596, std=0.008869 using {'adapt_embedding': False, 'filters': 100, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.281, std=0.03609 using {'adapt_embedding': False, 'filters': 100, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      " mean=0.2853, std=0.02813 using {'adapt_embedding': False, 'filters': 100, 'kernel': 5, 'mood_count': 4, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f26785d87c0>}\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "test_dataset(\"./data/song-data-labels-cleaned-quadrant.csv\",4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af4d176",
   "metadata": {},
   "source": [
    "## Test the dataset with normalized moods and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2539b4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing now dataset ./data/song-data-labels-cleaned-seven-moods.csv with 7 moods\n",
      "['romantic' 'happy' 'sad' 'enthusiastic' 'calm' 'depressed' 'anger']\n",
      "processsed: 500 rows out of 14308\n",
      "processsed: 1000 rows out of 14308\n",
      "processsed: 1500 rows out of 14308\n",
      "processsed: 2000 rows out of 14308\n",
      "processsed: 2500 rows out of 14308\n",
      "processsed: 3000 rows out of 14308\n",
      "processsed: 3500 rows out of 14308\n",
      "processsed: 4000 rows out of 14308\n",
      "processsed: 4500 rows out of 14308\n",
      "processsed: 5000 rows out of 14308\n",
      "processsed: 5500 rows out of 14308\n",
      "processsed: 6000 rows out of 14308\n",
      "processsed: 6500 rows out of 14308\n",
      "processsed: 7000 rows out of 14308\n",
      "processsed: 7500 rows out of 14308\n",
      "processsed: 8000 rows out of 14308\n",
      "processsed: 8500 rows out of 14308\n",
      "processsed: 9000 rows out of 14308\n",
      "processsed: 9500 rows out of 14308\n",
      "processsed: 10000 rows out of 14308\n",
      "processsed: 10500 rows out of 14308\n",
      "processsed: 11000 rows out of 14308\n",
      "processsed: 11500 rows out of 14308\n",
      "processsed: 12000 rows out of 14308\n",
      "processsed: 12500 rows out of 14308\n",
      "processsed: 13000 rows out of 14308\n",
      "processsed: 13500 rows out of 14308\n",
      "processsed: 14000 rows out of 14308\n",
      "[['lie', 'floor', 'feather', 'find', 'hand', 'wanna', 'believe', 'not', 'think', 's', 'god', 'heaven', 'hell', 'lose', 'lookin', 'sign', 'maybe', 'fool', 'swear', 'spine', 'get', 'shiver', 'like', 'kiss', 'time', 'tho', 'tear', 'stream', 'like', 'river', 'know', 'ask', 'sign', 'scare', 'tho', 'body', 'start', 'shakin', 'feel', 'dry', 'eye', 'tho', 'heart', 'break', 'know', 'love', 'sign', 'sign', 'findin', 'street', 'starin', 'reach', 'turn', 'lookin', 'stranger', 'eye', 's', 'god', 'heaven', 'hell', 'tt', 'feel', 'like', 'walk', 'cos', 'touch', 'like', 'swear', 'spine', 'get', 'shiver', 'like', 'kiss', 'time', 'tho', 'tear', 'stream', 'like', 'river', 'know', 'ask', 'sign', 'scare', 'tho', 'body', 'start', 'shakin', 'feel', 'dry', 'eye', 'tho', 'heart', 'break', 'know', 'love', 'sign', 'sign', 'lie', 'floor', 'feather', 'find', 'hand', 'wanna', 'believe', 'not', 'think', 'swear', 'spine', 'get', 'shiver', 'like', 'kiss', 'time', 'tho', 'tear', 'stream', 'like', 'river', 'know', 'ask', 'sign', 'scare', 'tho', 'body', 'start', 'shakin', 'feel', 'dry', 'eye', 'tho', 'heart', 'break', 'know', 'love', 'sign', 'sign'], ['left', 'left', 'left', 'left', 'box', 'left', 'closet', 'yes', 'stuff', 'yes', 'buy', 'touch', 'talk', 'mess', 's', 'fine', 'walk', 'talk', 'time', 'and-', 's', 'tag', 'bag', 'let', 'cab', 'standing', 'yard', 'tell', 'fool', 'talk', \"'bout\", 'find', 'man', 'like', 'get', 'twisted', 'know', 'know', 'minute', 'matter', 'fact', 'minute', 'know', 'know', 'tomorrow', 'second', 'thinkin', 'irreplaceable', 'ahead', 'grow', 'chick', 's', 'home', 'oops', 'bet', 'think', 'know', 'think', 'put', 'untrue', 'roll', 'car', 'buy', 'baby', 'drop', 'key', 'hurry', 'taxi', 'leave', 'stand', 'yard', 'tell', 'fool', 'talk', \"'bout\", 'find', 'man', 'like', 'get', 'twisted', 'know', 'know', 'minute', 'matter', 'fact', 'minute', 'know', 'know', 'tomorrow', 'second', 'thinkin', 'irreplaceable', 'baby', 'will', 'shed', 'tear', 'will', 'lose', 'wink', 'sleep', 'cause', 'truth', 'matter', 'replace', 'easy', 'left', 'left', 'left', 'left', 'mmmmmmmm', 'left', 'left', 'box', 'left', 'left', 'left', 'second', 'think', 'irreplaceable', 'know', 'know', 'minute', 'matter', 'fact', 'minute', 'know', 'know', 'tomorrow', 'second', 'thinkin', 'know', 'know', 'minute', 'matter', 'fact', 'minute', 'pack', 'things-', 'finish', 'cause', 'bed', 'lie', 'tomorrow', 'second', 'thinkin', 'irreplaceable']]\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0   19    3   19   39   59\n",
      "    18  109  137    1  478   53   20    8  138   58 1101    8  146  101\n",
      "    63  138  118    2   75   21   23  324    9  415   20   23  293  324\n",
      "    23   80    2    1   11   23    1  213   14    9  415   20   23   80\n",
      "    53 2257   33   53 2257   33   10   22  283  325    5   23    4 1115\n",
      "    10  773   20  139    8  138 1350   58  325   61   15    7  138  170\n",
      "    75   21   23  324    9  415   20   23  293  324   23   80    2    1\n",
      "    11   23    1  213   14    9  415   20   23   80   53 2257   33   53\n",
      "  2257   33   76   19   94   39   34   16   46    4   13  325  415   20\n",
      "   106  645  396  120   15   15   23   12    9  415   20   23  293   12\n",
      "    23   80    2    1   11   23    1  213   14    9  415   20   23   80\n",
      "    53 2257   33   53 2257   33   53 2257   33   53 2257   33]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0   19   27    3   68    8   22 1315   49  125\n",
      "     3  481   23   15  125  125  578    4   10   81    5   25   92  146\n",
      "   539   18   10   22  125    3  481   23   15   35  125  125  578    4\n",
      "    10  180  544  168  180    1  544  168  125    3  481   23   15   35\n",
      "   125  125  578    4   10  180  544  168  180    1  544  168]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20118/736918557.py:40: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model_CV = KerasClassifier(build_fn=create_model, epochs=epochs,\n",
      "2023-02-27 21:29:50.876810: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:50.876848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:50.876854: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:50.876855: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:50.876870: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:50.876870: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:50.876883: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:50.880311: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:51.279723: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:51.279796: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 21:29:51.280091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:51.280129: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 21:29:51.280322: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:51.280356: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 21:29:51.280758: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:51.280830: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 21:29:51.281447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:51.281619: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 21:29:51.282314: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:51.282415: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 21:29:51.283460: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:51.283515: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 21:29:51.285329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:51.285419: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 21:29:54.384829: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.385841: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.386046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 21:29:54.404285: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.404686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.404862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 21:29:54.407858: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.408308: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.408484: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 21:29:54.412250: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.413100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.413289: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 21:29:54.437200: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.437633: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.437959: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 21:29:54.440478: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.440689: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.440729: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 21:29:54.443523: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.443884: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.443999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-27 21:29:54.456687: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.457127: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:54.457373: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:29:58.467716: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:58.467716: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:58.467763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:58.467807: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 21:29:58.467806: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 21:29:58.467821: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 21:29:58.467850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 21:29:58.467855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 21:29:58.467854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 21:29:58.468370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:58.468370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:58.468999: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:58.567787: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:58.568019: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 21:29:58.568167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 21:29:58.570596: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:58.572557: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:58.572788: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 21:29:58.572885: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 21:29:58.573578: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:58.588318: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:58.588515: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 21:29:58.588603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 21:29:58.589274: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:58.889606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:58.890667: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 21:29:58.890852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 21:29:58.895763: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 21:29:58.924327: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-27 21:29:58.924837: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-27 21:29:58.925152: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-D6IC8GJA): /proc/driver/nvidia/version does not exist\n",
      "2023-02-27 21:29:58.926228: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:09.035606: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:09.035920: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:09.064958: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:09.065068: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:09.070663: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:09.070971: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:09.171108: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:09.190108: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/179 [..............................] - ETA: 26:28 - loss: 0.7232 - acc: 0.1250\r",
      "  1/179 [..............................] - ETA: 27:26 - loss: 0.6991 - acc: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:09.439260: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:09.440542: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:09.602865: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:09.606725: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/179 [..............................] - ETA: 27:53 - loss: 0.9823 - acc: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:09.855758: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:09.859101: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/179 [..............................] - ETA: 3:44 - loss: 0.5937 - acc: 0.0781 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:10.817823: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/179 [..............................] - ETA: 4:34 - loss: 2.1268 - acc: 0.1406 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:11.771151: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:11.772200: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:11.948466: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  3/179 [..............................] - ETA: 3:31 - loss: 0.5382 - acc: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:12.196173: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  3/179 [..............................] - ETA: 3:58 - loss: 2.0358 - acc: 0.1667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:12.614595: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:12.622927: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/179 [..............................] - ETA: 37:09 - loss: 1.3464 - acc: 0.0625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  3/179 [..............................] - ETA: 5:19 - loss: 0.5670 - acc: 0.1771"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:12.929278: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:12.945050: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  4/179 [..............................] - ETA: 4:17 - loss: 0.5217 - acc: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:14.123703: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:14.159198: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/179 [..............................] - ETA: 41:40 - loss: 1.4120 - acc: 0.1875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:14.511001: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:14.511288: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:14.573225: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:14.573458: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:14.598081: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:14.598388: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  6/179 [>.............................] - ETA: 3:06 - loss: 0.4982 - acc: 0.1458\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  4/179 [..............................] - ETA: 4:54 - loss: 1.9000 - acc: 0.1484\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  4/179 [..............................] - ETA: 5:18 - loss: 0.5756 - acc: 0.1562\r",
      "  1/179 [..............................] - ETA: 43:39 - loss: 0.7095 - acc: 0.1875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:15.140750: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:15.177407: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:15.525878: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/179 [..............................] - ETA: 45:24 - loss: 0.7005 - acc: 0.2188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  5/179 [..............................] - ETA: 4:32 - loss: 0.5517 - acc: 0.1562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:15.877355: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/179 [..............................] - ETA: 4:43 - loss: 1.8324 - acc: 0.1375 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:16.548167: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/179 [..............................] - ETA: 6:45 - loss: 0.6295 - acc: 0.1875 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:17.143072: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 21420000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:17.293133: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n",
      "2023-02-27 21:30:17.293339: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/179 [>.............................] - ETA: 3:35 - loss: 0.5055 - acc: 0.1632"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 21:30:19.575693: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 23760000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 178s 947ms/step - loss: 0.4222 - acc: 0.1443\n",
      "169/179 [===========================>..] - ETA: 9s - loss: 0.4221 - acc: 0.1461 Epoch 2/3\n",
      "179/179 [==============================] - 182s 946ms/step - loss: 0.9241 - acc: 0.1464\n",
      "165/179 [==========================>...] - ETA: 14s - loss: 0.4262 - acc: 0.1403Epoch 2/3\n",
      "179/179 [==============================] - 186s 964ms/step - loss: 0.4219 - acc: 0.1438\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 188s 988ms/step - loss: 0.9100 - acc: 0.1518\n",
      "165/179 [==========================>...] - ETA: 14s - loss: 0.4227 - acc: 0.1403Epoch 2/3\n",
      "179/179 [==============================] - 194s 1s/step - loss: 0.4255 - acc: 0.1393\n",
      " 10/179 [>.............................] - ETA: 2:17 - loss: 0.4172 - acc: 0.1500Epoch 2/3\n",
      "179/179 [==============================] - 196s 1s/step - loss: 0.5800 - acc: 0.1414\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 198s 1s/step - loss: 1.2368 - acc: 0.1525\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 201s 1s/step - loss: 0.4218 - acc: 0.1422\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 148s 828ms/step - loss: 0.4129 - acc: 0.1660\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 139s 779ms/step - loss: 0.4126 - acc: 0.1417\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 149s 833ms/step - loss: 0.6606 - acc: 0.1478\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 146s 814ms/step - loss: 0.4150 - acc: 0.1508\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 163s 910ms/step - loss: 0.4153 - acc: 0.1433\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 163s 908ms/step - loss: 0.4141 - acc: 0.1373\n",
      "  1/179 [..............................] - ETA: 3:05 - loss: 0.4111 - acc: 0.0938Epoch 3/3\n",
      "179/179 [==============================] - 161s 901ms/step - loss: 0.7568 - acc: 0.1396\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 163s 912ms/step - loss: 0.4131 - acc: 0.1571\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 144s 802ms/step - loss: 0.4056 - acc: 0.1936\n",
      "179/179 [==============================] - 143s 799ms/step - loss: 0.4116 - acc: 0.1443\n",
      "179/179 [==============================] - 142s 794ms/step - loss: 0.6589 - acc: 0.1569\n",
      "179/179 [==============================] - 143s 797ms/step - loss: 0.4121 - acc: 0.1630\n",
      "179/179 [==============================] - 139s 777ms/step - loss: 0.4120 - acc: 0.1499\n",
      "179/179 [==============================] - 140s 783ms/step - loss: 0.4111 - acc: 0.1758\n",
      "179/179 [==============================] - 138s 773ms/step - loss: 0.6635 - acc: 0.1620\n",
      "179/179 [==============================] - 24s 112ms/step - loss: 0.6813 - acc: 0.1421\n",
      "179/179 [==============================] - 135s 755ms/step - loss: 0.4007 - acc: 0.2231\n",
      " 18/179 [==>...........................] - ETA: 7s - loss: 0.4006 - acc: 0.2309Epoch 1/3\n",
      "179/179 [==============================] - 10s 49ms/step - loss: 0.4081 - acc: 0.1974\n",
      "179/179 [==============================] - 10s 49ms/step - loss: 0.3993 - acc: 0.2286\n",
      "Epoch 1/3\n",
      "  2/179 [..............................] - ETA: 48s - loss: 1.4844 - acc: 0.1719  Epoch 1/3\n",
      "179/179 [==============================] - 33s 171ms/step - loss: 0.4051 - acc: 0.2319\n",
      "179/179 [==============================] - 35s 184ms/step - loss: 0.4080 - acc: 0.2009\n",
      "179/179 [==============================] - 36s 188ms/step - loss: 0.4104 - acc: 0.1428\n",
      "179/179 [==============================] - 41s 217ms/step - loss: 0.4157 - acc: 0.1429\n",
      "179/179 [==============================] - 40s 205ms/step - loss: 0.6717 - acc: 0.1428\n",
      " 37/179 [=====>........................] - ETA: 3:09 - loss: 1.3115 - acc: 0.1495Epoch 1/3\n",
      " 40/179 [=====>........................] - ETA: 3:06 - loss: 1.2790 - acc: 0.1500Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "Epoch 1/3\n",
      "179/179 [==============================] - 288s 2s/step - loss: 0.8573 - acc: 0.1331\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 321s 2s/step - loss: 1.3550 - acc: 0.1417\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 329s 2s/step - loss: 0.4222 - acc: 0.1414\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 372s 2s/step - loss: 0.4201 - acc: 0.1449\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 432s 2s/step - loss: 0.4199 - acc: 0.1492\n",
      "179/179 [==============================] - ETA: 0s - loss: 0.4210 - acc: 0.1401Epoch 2/3\n",
      "179/179 [==============================] - 432s 2s/step - loss: 0.4210 - acc: 0.1401\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 433s 2s/step - loss: 3.7627 - acc: 0.1431\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 437s 2s/step - loss: 3.7503 - acc: 0.1419\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 338s 2s/step - loss: 0.6740 - acc: 0.1403\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 345s 2s/step - loss: 0.4828 - acc: 0.1403\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 343s 2s/step - loss: 0.4145 - acc: 0.1452\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 334s 2s/step - loss: 0.4111 - acc: 0.1709\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 383s 2s/step - loss: 0.4139 - acc: 0.1518\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 388s 2s/step - loss: 3.7515 - acc: 0.1438\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 389s 2s/step - loss: 0.4125 - acc: 0.1615\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 387s 2s/step - loss: 3.7603 - acc: 0.1419\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 317s 2s/step - loss: 0.6721 - acc: 0.1646\n",
      "179/179 [==============================] - 316s 2s/step - loss: 0.4120 - acc: 0.1426\n",
      "179/179 [==============================] - 315s 2s/step - loss: 0.4082 - acc: 0.1929\n",
      "179/179 [==============================] - 317s 2s/step - loss: 0.3989 - acc: 0.2144\n",
      "179/179 [==============================] - 102s 541ms/step - loss: 0.4104 - acc: 0.1429\n",
      "179/179 [==============================] - 103s 552ms/step - loss: 0.6578 - acc: 0.1950\n",
      "101/179 [===============>..............] - ETA: 2:48 - loss: 0.4058 - acc: 0.1983Epoch 1/3\n",
      "179/179 [==============================] - 111s 592ms/step - loss: 0.3997 - acc: 0.2237\n",
      " 21/179 [==>...........................] - ETA: 56s - loss: 0.3895 - acc: 0.2857Epoch 1/3\n",
      "143/179 [======================>.......] - ETA: 1:14 - loss: 3.7553 - acc: 0.1431Epoch 1/3\n",
      "179/179 [==============================] - 81s 423ms/step - loss: 0.3921 - acc: 0.2452\n",
      "167/179 [==========================>...] - ETA: 24s - loss: 0.4035 - acc: 0.2047Epoch 1/3\n",
      "179/179 [==============================] - 355s 2s/step - loss: 0.4080 - acc: 0.1938\n",
      "179/179 [==============================] - 357s 2s/step - loss: 3.7526 - acc: 0.1438\n",
      "179/179 [==============================] - 359s 2s/step - loss: 0.4031 - acc: 0.2069\n",
      "179/179 [==============================] - 358s 2s/step - loss: 3.7603 - acc: 0.1419\n",
      "179/179 [==============================] - 150s 567ms/step - loss: 0.9688 - acc: 0.1401\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 153s 569ms/step - loss: 1.3179 - acc: 0.1457\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 156s 599ms/step - loss: 0.4246 - acc: 0.1338\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 94s 509ms/step - loss: 0.3964 - acc: 0.2362\n",
      "179/179 [==============================] - 93s 505ms/step - loss: 3.7519 - acc: 0.1438\n",
      "179/179 [==============================] - 94s 514ms/step - loss: 0.3986 - acc: 0.2354\n",
      "146/179 [=======================>......] - ETA: 22s - loss: 0.4133 - acc: 0.1432Epoch 1/3\n",
      " 76/179 [===========>..................] - ETA: 1:13 - loss: 1.1804 - acc: 0.1427Epoch 1/3\n",
      "179/179 [==============================] - 96s 505ms/step - loss: 3.7603 - acc: 0.1419\n",
      "179/179 [==============================] - 110s 616ms/step - loss: 0.4132 - acc: 0.1459\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 146s 629ms/step - loss: 0.4218 - acc: 0.1443\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 102s 565ms/step - loss: 1.1858 - acc: 0.1464\n",
      " 33/179 [====>.........................] - ETA: 1:28 - loss: 1.1259 - acc: 0.1629Epoch 3/3\n",
      " 63/179 [=========>....................] - ETA: 1:00 - loss: 0.4154 - acc: 0.1513Epoch 1/3\n",
      " 18/179 [==>...........................] - ETA: 1:34 - loss: 1.1310 - acc: 0.1476Epoch 1/3\n",
      "179/179 [==============================] - 95s 528ms/step - loss: 0.4133 - acc: 0.1718\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 98s 545ms/step - loss: 0.4108 - acc: 0.1711\n",
      "179/179 [==============================] - 107s 599ms/step - loss: 0.4145 - acc: 0.1524\n",
      "124/179 [===================>..........] - ETA: 34s - loss: 1.1891 - acc: 0.1530Epoch 3/3\n",
      "179/179 [==============================] - 34s 159ms/step - loss: 0.4093 - acc: 0.1983\n",
      " 70/179 [==========>...................] - ETA: 1:25 - loss: 0.4332 - acc: 0.1228Epoch 1/3\n",
      "179/179 [==============================] - 152s 691ms/step - loss: 0.7669 - acc: 0.1501\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 152s 694ms/step - loss: 0.5167 - acc: 0.1468\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 118s 659ms/step - loss: 1.1167 - acc: 0.1503\n",
      "179/179 [==============================] - 34s 157ms/step - loss: 0.6662 - acc: 0.1400\n",
      "179/179 [==============================] - 123s 688ms/step - loss: 0.4065 - acc: 0.2128\n",
      "137/179 [=====================>........] - ETA: 31s - loss: 0.4268 - acc: 0.1405Epoch 1/3\n",
      "179/179 [==============================] - 173s 720ms/step - loss: 0.4237 - acc: 0.1347\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 177s 734ms/step - loss: 0.4242 - acc: 0.1414\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 32s 153ms/step - loss: 0.4098 - acc: 0.1884\n",
      "125/179 [===================>..........] - ETA: 38s - loss: 0.4138 - acc: 0.1532Epoch 1/3\n",
      "179/179 [==============================] - 117s 655ms/step - loss: 0.4087 - acc: 0.1803\n",
      "179/179 [==============================] - 121s 673ms/step - loss: 0.6647 - acc: 0.1419\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 121s 678ms/step - loss: 0.4134 - acc: 0.1489\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 32s 148ms/step - loss: 0.4085 - acc: 0.1843\n",
      "174/179 [============================>.] - ETA: 3s - loss: 0.4157 - acc: 0.1424Epoch 1/3\n",
      "179/179 [==============================] - 120s 669ms/step - loss: 0.4156 - acc: 0.1431\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 117s 655ms/step - loss: 0.4121 - acc: 0.1784\n",
      " 11/179 [>.............................] - ETA: 1:55 - loss: 0.4124 - acc: 0.1648Epoch 3/3\n",
      "179/179 [==============================] - 126s 707ms/step - loss: 0.6637 - acc: 0.1553\n",
      "179/179 [==============================] - 127s 712ms/step - loss: 0.4108 - acc: 0.1611\n",
      "179/179 [==============================] - 36s 178ms/step - loss: 0.4136 - acc: 0.1429\n",
      "179/179 [==============================] - 36s 170ms/step - loss: 0.6702 - acc: 0.1534\n",
      "175/179 [============================>.] - ETA: 5s - loss: 1.1441 - acc: 0.1429Epoch 1/3\n",
      "179/179 [==============================] - 306s 1s/step - loss: 1.1377 - acc: 0.1424\n",
      "Epoch 2/3\n",
      "175/179 [============================>.] - ETA: 2s - loss: 0.4126 - acc: 0.16326Epoch 1/3\n",
      "179/179 [==============================] - 119s 667ms/step - loss: 0.4127 - acc: 0.1634\n",
      "179/179 [==============================] - 117s 655ms/step - loss: 0.3995 - acc: 0.2301\n",
      "179/179 [==============================] - 27s 127ms/step - loss: 0.4107 - acc: 0.1515\n",
      "179/179 [==============================] - 303s 1s/step - loss: 2.1988 - acc: 0.1426\n",
      "Epoch 2/3\n",
      "166/179 [==========================>...] - ETA: 1s - loss: 0.3940 - acc: 0.2515Epoch 1/3\n",
      "179/179 [==============================] - 31s 154ms/step - loss: 0.3941 - acc: 0.2499\n",
      " 23/179 [==>...........................] - ETA: 4:19 - loss: 1.7586 - acc: 0.1644Epoch 1/3\n",
      "179/179 [==============================] - 294s 1s/step - loss: 0.4222 - acc: 0.1380\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 310s 1s/step - loss: 0.4211 - acc: 0.1468\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 261s 1s/step - loss: 0.9148 - acc: 0.1515\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 285s 2s/step - loss: 2.2039 - acc: 0.1428\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 373s 2s/step - loss: 3.7461 - acc: 0.1415\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 290s 2s/step - loss: 0.4141 - acc: 0.1567\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 372s 2s/step - loss: 1.7108 - acc: 0.1435\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 386s 2s/step - loss: 0.4252 - acc: 0.1380\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 391s 2s/step - loss: 0.4217 - acc: 0.1457\n",
      "Epoch 2/3\n",
      "179/179 [==============================] - 293s 2s/step - loss: 0.4131 - acc: 0.1578\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 288s 2s/step - loss: 0.9141 - acc: 0.1611\n",
      "179/179 [==============================] - 281s 2s/step - loss: 2.2039 - acc: 0.1428\n",
      "179/179 [==============================] - 269s 2s/step - loss: 0.4049 - acc: 0.2139\n",
      "179/179 [==============================] - 69s 343ms/step - loss: 0.9325 - acc: 0.1449\n",
      "179/179 [==============================] - 314s 2s/step - loss: 3.7603 - acc: 0.1419\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 313s 2s/step - loss: 1.3599 - acc: 0.1407\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 70s 360ms/step - loss: 2.2036 - acc: 0.1429\n",
      "179/179 [==============================] - 251s 1s/step - loss: 0.4056 - acc: 0.1919\n",
      "179/179 [==============================] - 299s 2s/step - loss: 0.4152 - acc: 0.1410\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 65s 327ms/step - loss: 0.3953 - acc: 0.2362\n",
      "179/179 [==============================] - 287s 2s/step - loss: 0.4144 - acc: 0.1510\n",
      "Epoch 3/3\n",
      "179/179 [==============================] - 52s 266ms/step - loss: 0.4044 - acc: 0.2023\n",
      "179/179 [==============================] - 208s 1s/step - loss: 3.7603 - acc: 0.1419\n",
      "179/179 [==============================] - 204s 1s/step - loss: 0.5673 - acc: 0.1396\n",
      "179/179 [==============================] - 179s 997ms/step - loss: 0.4103 - acc: 0.1808\n",
      "179/179 [==============================] - 173s 965ms/step - loss: 0.4116 - acc: 0.1658\n",
      "179/179 [==============================] - 38s 203ms/step - loss: 3.7519 - acc: 0.1438\n",
      "179/179 [==============================] - 33s 168ms/step - loss: 0.4104 - acc: 0.1438\n",
      "179/179 [==============================] - 12s 59ms/step - loss: 0.4052 - acc: 0.2168\n",
      "179/179 [==============================] - 11s 57ms/step - loss: 0.3983 - acc: 0.2348\n",
      "Epoch 1/3\n",
      "358/358 [==============================] - 108s 276ms/step - loss: 0.4189 - acc: 0.1407\n",
      "Epoch 2/3\n",
      "358/358 [==============================] - 94s 262ms/step - loss: 0.4063 - acc: 0.1919\n",
      "Epoch 3/3\n",
      "358/358 [==============================] - 95s 264ms/step - loss: 0.3899 - acc: 0.2489\n",
      "Best Accuracy for dataset ./data/song-data-labels-cleaned-seven-moods.csv is: 0.23580289632081985 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.1424, std=0.0003495 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.2164, std=0.01546 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.1428, std=8.737e-05 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.213, std=0.01555 using {'adapt_embedding': True, 'filters': 50, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.169, std=0.02604 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.2344, std=0.01075 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.1428, std=0.000961 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.2358, std=0.0004368 using {'adapt_embedding': True, 'filters': 100, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.1691, std=0.02918 using {'adapt_embedding': False, 'filters': 50, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.1864, std=0.002009 using {'adapt_embedding': False, 'filters': 50, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.1482, std=0.005242 using {'adapt_embedding': False, 'filters': 50, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.2007, std=0.04919 using {'adapt_embedding': False, 'filters': 50, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.1439, std=0.000961 using {'adapt_embedding': False, 'filters': 100, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.2193, std=0.01695 using {'adapt_embedding': False, 'filters': 100, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 3, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.1438, std=0.0 using {'adapt_embedding': False, 'filters': 100, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'relu', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      " mean=0.2258, std=0.008999 using {'adapt_embedding': False, 'filters': 100, 'kernel': 5, 'mood_count': 7, 'multiplicator': 2, 'multiplicator2': 4, 'outputfunction': 'softmax', 'wrd2vecmodel': <gensim.models.word2vec.Word2Vec object at 0x7f267810ea10>}\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "test_dataset(\"./data/song-data-labels-cleaned-seven-moods.csv\", 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcaafdd",
   "metadata": {},
   "source": [
    "# Sample prediction\n",
    "Code might be broken due to heavy restructuring of the notebook, but it should only assist as a \"documentation\" for us developers anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f391ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def tokenization(text: list[spacy.tokens.token.Token]) -> list[spacy.tokens.token.Token]:\n",
    "    \"\"\"Use this function to tokenize text.\n",
    "\n",
    "    :param text: Text as list\n",
    "    :type text: list[spacy.tokens.token.Token]\n",
    "    :return: Tokenized text as list\n",
    "    :rtype: list[spacy.tokens.token.Token]\n",
    "    \"\"\"\n",
    "\n",
    "    token_list = []\n",
    "    for doc in text: \n",
    "        # iterate over tokens in docs\n",
    "        for token in doc:\n",
    "            token_list.append(token)\n",
    "\n",
    "    return token_list\n",
    "\n",
    "\n",
    "def stop_word_removal(text: list[spacy.tokens.token.Token]) -> list[spacy.tokens.token.Token]: \n",
    "    \"\"\"Use this function to remove stop words. \n",
    "\n",
    "    :param text: Tokens to remove stop words from \n",
    "    :type text: list[spacy.tokens.token.Token]\n",
    "    :return: Tokens without stop words\n",
    "    :rtype: list[spacy.tokens.token.Token]\n",
    "    \"\"\"\n",
    "\n",
    "    token_list_without_stop = []\n",
    "    # Don't add token to list if stop word\n",
    "    for token in text:\n",
    "        if token.is_stop == False: \n",
    "            token_list_without_stop.append(token)\n",
    "\n",
    "    return token_list_without_stop\n",
    "\n",
    "\n",
    "def punctutation_removal(text: list[spacy.tokens.token.Token]) -> list[spacy.tokens.token.Token]: \n",
    "    \"\"\"Use this function to remove punctuation.\n",
    "\n",
    "    :param text: Tokens to remove punctuation from\n",
    "    :type text: list[spacy.tokens.token.Token]\n",
    "    :return: Tokens without punctuation\n",
    "    :rtype: list[spacy.tokens.token.Token]\n",
    "    \"\"\"\n",
    "\n",
    "    token_list_no_stop_no_punct = []\n",
    "    # Don't add token to list if punctuation\n",
    "    for token in text:\n",
    "        if token.is_punct == False:\n",
    "            token_list_no_stop_no_punct.append(token)\n",
    "\n",
    "    return token_list_no_stop_no_punct\n",
    "\n",
    "\n",
    "def lemmatization(text: list[spacy.tokens.token.Token]) -> list[str]: \n",
    "    \"\"\"Use this function to lemmatize a given text.\n",
    "\n",
    "    :param text: Tokens to lemmatize\n",
    "    :type text: list[spacy.tokens.token.Token]\n",
    "    :return: lemmatized tokens\n",
    "    :rtype: list[str]\n",
    "    \"\"\"\n",
    "\n",
    "    token_list_no_stop_no_punct_lemmatized = []\n",
    "    for token in text: \n",
    "        if \"\\n\" not in token.lemma_:\n",
    "            token_list_no_stop_no_punct_lemmatized.append(token.lemma_)\n",
    "    return token_list_no_stop_no_punct_lemmatized\n",
    "\n",
    "\n",
    "def processing_pipeline(song_data: dict) -> dict:\n",
    "    \"\"\"Use this function to execute the entire processing pipeline on given song data.\n",
    "    Preprocessing steps:\n",
    "    - Tokenization\n",
    "    - Stop word removal\n",
    "    - Punctuation removal\n",
    "    - Lemmatization\n",
    "\n",
    "    :param song_data: song data saved in a json file containing song name, artist name and lyrics\n",
    "    :type song_data: dict\n",
    "    :return: preprocessed song data\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable = ['ner'])\n",
    "    text_nlp_pipe = list(nlp.pipe([song_data[\"Lyrics\"]]))\n",
    "    \n",
    "    # Tokenization\n",
    "    song_data[\"Lyrics\"] = tokenization(text_nlp_pipe)\n",
    "    # Stop word removal\n",
    "    song_data[\"Lyrics\"] = stop_word_removal(song_data[\"Lyrics\"])\n",
    "    # Punctuation removal\n",
    "    song_data[\"Lyrics\"] = punctutation_removal(song_data[\"Lyrics\"])\n",
    "    # Lemmatization\n",
    "    song_data[\"Lyrics\"] = lemmatization(song_data[\"Lyrics\"])\n",
    "\n",
    "    return song_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "578cbdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model:\n",
    "test_song = {\n",
    "        \"Song\": \"Mockingbird\",\n",
    "        \"Artist\": \"Eminem\",\n",
    "        \"Lyrics\": (\n",
    "            \"\"\"Yeah\n",
    "            I know sometimes things may not always make sense to you right now\n",
    "            But hey, what daddy always tell you?\n",
    "            Straighten up little soldier\n",
    "            Stiffen up that upper lip\n",
    "            What you crying about?\n",
    "            You got me\n",
    "            Hailie, I know you miss your mom, and I know you miss your dad\n",
    "            When I'm gone, but I'm trying to give you the life that I never had\n",
    "            I can see you're sad, even when you smile, even when you laugh\n",
    "            I can see it in your eyes, deep inside you want to cry\n",
    "            'Cause you're scared, I ain't there, daddy's with you in your prayers\n",
    "            No more crying, wipe them tears, daddy's here, no more nightmares\n",
    "            We gon' pull together through it, we gon' do it\n",
    "            Laney uncle's crazy, ain't he? Yeah, but he loves you girl and you better know it\n",
    "            We're all we got in this world, when it spins, when it swirls\n",
    "            When it whirls, when it twirls, two little beautiful girls\n",
    "            Lookin' puzzled, in a daze, I know it's confusing you\n",
    "            Daddy's always on the move, mamma's always on the news\n",
    "            I try to keep you sheltered from it, but somehow it seems\n",
    "            The harder that I try to do that, the more it backfires on me\n",
    "            All the things growing up, his daddy, daddy had to see\n",
    "            Daddy don't want you to see, but you see just as much as he did\n",
    "            We did not plan it to be this way, your mother and me\n",
    "            But things have gotten so bad between us, I don't see us ever being together\n",
    "            Ever again like we used to be when we was teenagers\n",
    "            But then of course everything always happens for a reason\n",
    "            I guess it was never meant to be\n",
    "            But it's just something we have no control, over and that's what destiny is\n",
    "            But no more worries, rest your head and go to sleep\n",
    "            Maybe one day we'll wake up, and this will all just be a dream\n",
    "            Now hush little baby, don't you cry\n",
    "            Everything's gonna be alright\n",
    "            Stiffen that upper-lip up, little lady, I told ya\n",
    "            Daddy's here to hold ya through the night\n",
    "            I know mommy's not here right now, and we don't know why\n",
    "            We fear how we feel inside\n",
    "            It may seem a little crazy, pretty baby\n",
    "            But I promise momma's gon' be alright\n",
    "            Huh, it's funny\n",
    "            I remember back one year when daddy had no money\n",
    "            Mommy wrapped the Christmas presents up and stuck 'em under the tree\n",
    "            And said, \"Some of 'em were from me, 'cause Daddy couldn't buy 'em\"\n",
    "            I'll never forget that Christmas, I sat up the whole night crying\n",
    "            'Cause daddy felt like a bum\n",
    "            See daddy had a job\n",
    "            But his job was to keep the food on the table for you and mom\n",
    "            And at the time every house that we lived in\n",
    "            Either kept getting broke into and robbed\n",
    "            Or shot up on the block\n",
    "            And your Mom was saving money for you in a jar\n",
    "            Tryna start a piggy bank for you, so you could go to college\n",
    "            Almost had a thousand dollars 'til someone broke in and stole it\n",
    "            And I know it hurt so bad, it broke your momma's heart\n",
    "            And it seemed like everything was just startin' to fall apart\n",
    "            Mom and dad was arguin' a lot, so momma moved back\n",
    "            On the Chalmers in the flat one-bedroom apartment\n",
    "            And dad moved back to the other side of 8 Mile on Novara\n",
    "            And that's when daddy went to California with his C.D\n",
    "            And met Dr. Dre, and flew you and momma out to see me\n",
    "            But daddy had to work, you and momma had to leave me\n",
    "            Then you started seeing daddy on the T.V\n",
    "            And momma didn't like it, and you and Laney were to young to understand it\n",
    "            Papa was a rollin' stone, momma developed a habit\n",
    "            And it all happened too fast for either one of us to grab it\n",
    "            I'm just sorry you were there and had to witness it first hand\n",
    "            'Cause all I ever wanted to do was just make you proud\n",
    "            Now I'm sittin' in this empty house\n",
    "            Just reminiscing, lookin' at your baby pictures\n",
    "            It just trips me out\n",
    "            To see how much you both have grown\n",
    "            It's almost like you're sisters now\n",
    "            Wow, guess you pretty much are, and daddy's still here\n",
    "            Laney, I'm talkin' to you too, daddy's still here\n",
    "            I like the sound of that, yeah, It's got a ring to it, don't it?\n",
    "            Shh, momma's only gone for the moment\n",
    "            Now hush little baby, don't you cry\n",
    "            Everything's gonna be alright\n",
    "            Stiffen that upper-lip up, little lady, I told ya\n",
    "            Daddy's here to hold ya through the night\n",
    "            I know mommy's not here right now, and we don't know why\n",
    "            We fear how we feel inside\n",
    "            It may seem a little crazy, pretty baby\n",
    "            But I promise, momma's gon' be alright\n",
    "            And if you ask me too\n",
    "            Daddy's gonna buy you a Mockingbird\n",
    "            I'ma give you the world\n",
    "            I'ma buy a diamond ring for you, I'ma sing for you\n",
    "            I'll do anything for you to see you smile\n",
    "            And if that Mockingbird don't sing, and that ring don't shine\n",
    "            I'ma break that birdies neck\n",
    "            I'd go back to the jeweler who sold it to ya\n",
    "            And make him eat every karat, don't fuck with dad (haha)\"\"\"\n",
    "        ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8781897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_song = processing_pipeline(test_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b0c51077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yeah', 'know', 'thing', 'sense', 'right', 'hey', 'daddy', 'tell', 'straighten', 'little', 'soldier', 'Stiffen', 'upper', 'lip', 'cry', 'get', 'Hailie', 'know', 'miss', 'mom', 'know', 'miss', 'dad', 'go', 'try', 'life', 'sad', 'smile', 'laugh', 'eye', 'deep', 'inside', 'want', 'cry', \"'cause\", 'scared', 'be', 'daddy', 'prayer', 'crying', 'wipe', 'tear', 'daddy', 'nightmare', 'gon', 'pull', 'gon', 'Laney', 'uncle', 'crazy', 'be', 'yeah', 'love', 'girl', 'well', 'know', 'get', 'world', 'spin', 'swirl', 'whirl', 'twirl', 'little', 'beautiful', 'girl', 'Lookin', 'puzzle', 'daze', 'know', 'confuse', 'Daddy', 'mamma', 'news', 'try', 'shelter', 'hard', 'try', 'backfire', 'thing', 'grow', 'daddy', 'daddy', 'daddy', 'want', 'plan', 'way', 'mother', 'thing', 'get', 'bad', 'like', 'teenager', 'course', 'happen', 'reason', 'guess', 'mean', 'control', 'destiny', 'worry', 'rest', 'head', 'sleep', 'maybe', 'day', 'wake', 'dream', 'hush', 'little', 'baby', 'cry', 'go', 'to', 'alright', 'Stiffen', 'upper', 'lip', 'little', 'lady', 'tell', 'ya', 'Daddy', 'hold', 'ya', 'night', 'know', 'mommy', 'right', 'know', 'fear', 'feel', 'inside', 'little', 'crazy', 'pretty', 'baby', 'promise', 'momma', 'gon', 'alright', 'Huh', 'funny', 'remember', 'year', 'daddy', 'money', 'Mommy', 'wrap', 'Christmas', 'present', 'stick', 'them', 'tree', 'say', 'them', \"'cause\", 'daddy', 'buy', 'them', 'forget', 'Christmas', 'sit', 'night', 'cry', \"'cause\", 'daddy', 'feel', 'like', 'bum', 'daddy', 'job', 'job', 'food', 'table', 'mom', 'time', 'house', 'live', 'keep', 'getting', 'break', 'rob', 'shoot', 'block', 'Mom', 'save', 'money', 'jar', 'Tryna', 'start', 'piggy', 'bank', 'college', 'thousand', 'dollar', 'til', 'break', 'steal', 'know', 'hurt', 'bad', 'break', 'momma', 'heart', 'like', 'startin', 'fall', 'apart', 'Mom', 'dad', 'arguin', 'lot', 'momma', 'move', 'Chalmers', 'flat', 'bedroom', 'apartment', 'dad', 'move', '8', 'Mile', 'Novara', 'daddy', 'go', 'California', 'C.D', 'meet', 'Dr.', 'Dre', 'fly', 'momma', 'daddy', 'work', 'momma', 'leave', 'start', 'see', 'daddy', 'T.V', 'momma', 'like', 'Laney', 'young', 'understand', 'Papa', 'rollin', 'stone', 'momma', 'develop', 'habit', 'happen', 'fast', 'grab', 'sorry', 'witness', 'hand', \"'cause\", 'want', 'proud', 'sittin', 'house', 'reminiscing', 'lookin', 'baby', 'picture', 'trip', 'grow', 'like', 'sister', 'wow', 'guess', 'pretty', 'daddy', 'Laney', 'talkin', 'daddy', 'like', 'sound', 'yeah', 'get', 'ring', 'Shh', 'momma', 'go', 'moment', 'hush', 'little', 'baby', 'cry', 'go', 'to', 'alright', 'Stiffen', 'upper', 'lip', 'little', 'lady', 'tell', 'ya', 'Daddy', 'hold', 'ya', 'night', 'know', 'mommy', 'right', 'know', 'fear', 'feel', 'inside', 'little', 'crazy', 'pretty', 'baby', 'promise', 'momma', 'gon', 'alright', 'ask', 'Daddy', 'go', 'to', 'buy', 'Mockingbird', 'world', 'buy', 'diamond', 'ring', 'sing', 'smile', 'Mockingbird', 'sing', 'ring', 'shine', 'break', 'birdie', 'neck', 'jeweler', 'sell', 'ya', 'eat', 'karat', 'fuck', 'dad', 'haha']\n"
     ]
    }
   ],
   "source": [
    "print(processed_song[\"Lyrics\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e72b5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the tokenizer\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    token = pickle.load(handle)\n",
    "# tokenize\n",
    "text = token.texts_to_sequences([processed_song[\"Lyrics\"]])\n",
    "text = pad_sequences(text, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1f801eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  179    26    60    62   447    10     3  1320   447   775   775  1071\n",
      "    855  1017     8   265    41   218  1169    53  1722   413   869  1017\n",
      "    156   211  2485  1636    82  6451  1412  3248   459   900   285    53\n",
      "    371     2   136    98    53  1139    21     3  2863    37   258  1017\n",
      "    906 17626   304  1139   255  1561  1258  2518   906   255  1689   392\n",
      "    447     4   929   147  2364   126  1139   447   150  1139    24    82\n",
      "     73   447  1139     3 19532   189   162  1033  1047   314  1139  6769\n",
      "   1766   232   242   702   291  1315    49    62     9   757  1193   265\n",
      "  14576   528    14   365   664   180     3   601  1212   208   267   447\n",
      "  19532   603   447     3   167    18     6   317  6076  1139     4   249\n",
      "   1099    43    14    60     4    13   166  9315  3856   334    43   313\n",
      "     20   110   447    40   110    26     2  2008    27     2   159    10\n",
      "     64    43   182   267    14   262  1139   571   166   140   447     4\n",
      "     13   349 12588    33   349   638   317   121   124 12588   121   317\n",
      "    144    53  7780   797  8104   445   110   424 12472   153   906  3373]]\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "70e71d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = keras_model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1a8601a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03035141 0.07305858 0.01072862 0.00733498 0.10687384 0.01872347\n",
      "  0.00504669 0.09882194 0.00760916 0.00933376 0.00872805 0.02308791\n",
      "  0.19617064 0.00064153 0.08658496 0.19915532 0.11774925]]\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "# propability distr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "de5d65b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mood=np.argmax(pred,axis=1)\n",
    "# get the mood that is predicted the most "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0a0dde91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\n"
     ]
    }
   ],
   "source": [
    "print(pred_mood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1dc196a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sad']\n"
     ]
    }
   ],
   "source": [
    "# load the label encoder\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.classes_ = np.load('data/label_encoder.npy', allow_pickle=True)\n",
    "\n",
    "print(encoder.inverse_transform(pred_mood))\n",
    "# reverse transform the mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac45eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "cc1f558fa75d74d13a110a756bf00a1a7a77d8327c013f6ebbe6af7a56ad119a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
